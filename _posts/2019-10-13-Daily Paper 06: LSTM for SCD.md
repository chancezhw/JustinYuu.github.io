---
layout: post
title: "Daily Paper 06: LSTM for SCD"
description: "Notes"
categories: [SR-SCD]
tags: [Paper]
redirect_from:
  - /2019/10/13/
---

# Daily Paper 06 - Speaker Change Detection in Broadcast TV Using Bidirectional Long Short-Term Memory Networks  

## Introduction  

这篇paper来自法国牛校萨克雷大学，由于这是17年的论文，所以研究的成果可能看起来比之前19年的paper要简单一些，这里主要的研究内容是将Bi-LSTM应用到了SCD问题中，他们使用该idea，基于EPAPE语料库中的广播电视训练集训练了一个新系统，表现比传统的基于BIC和Gaussian Divergence的效果更好。  

LSTM在SCD得到了相当广泛的应用，基于LSTM和卷积神经网络的语音识别系统能够几乎达到人类水平的准确率，但是目前的speaker diarization系统仍然没有充分利用这一方法进行性能的改善，之前对于这一领域的研究也只是停留在应用神经网络对MFCC的特征识别进行优化，并没有改进说话者改变的检测部分。具体来讲，之前的SCD探测系统都是通过计算两个滑动窗口之间的距离，来用一个阈值判断是否发生了说话者的改变，而阈值的确定和距离的计算一般使用BIC和Gaussian divergence来确定，它们的表现优异，并且不需要预训练和阈值调优，总之既有效又方便。  

此外，还有一系列研究对传统的SCD系统进行了改善，比如著名的i-vector和作者之前提出的使用RNN网络进行特征空间映射改进的系统TristouNet，但是这些研究的不足之处在于他们依靠时长较长的连续滑动窗口(一般大于2s)，因此这些系统在短时长的交谈中会错过很多说话者切换。因此作者拟将SCD任务看作序列标记任务，使用在语音识别表现很好的Bi-LSTM处理SCD问题。  

## Syetem  

首先将音频看做序列进行标注，整个语音片段提取的特征可以被分为若干份，每一份只有几微米长，我们称之为滑动窗口，也叫做帧frame，之后将SCD任务看做是二分标注任务，1代表发生了speaker改变，0则反之，作者采用交叉熵损失函数，对RNN进行训练。RNN的结构是由两个Bi-LSTM和一个多层感知机组成，感知机的权重在整个网络中共享，两个Bi-LSTM其实就是一个双层的LSTM，感知机由三个FC层组成，前两个损失函数为tanh，第三个用sigmoid从而得到二元输出。可以看出整个RNN的结构还是非常简单的。  

由于frame非常短，所以正样本（也就是用户切换的样本）占比非常小，在ETAPE上的训练的结果显示只有0.4%的样本被判定为正，这就导致了训练过程中出现的样本正负的不平衡问题。此外，由于标注是由人工进行的，也就是通过人为判定是否发生了说话者的改变，但是frame被分的非常短，导致人为判定很可能会判断不准究竟是在哪一个frame发生了变化，这就会导致ground-truth准确率的大大降低，这也使得几乎所有的衡量指标都将人工标注的边界周围的一段时长（最多可以到半秒）看做变化的正确时刻，同时这也导致了正样本数量的显著增加，从而用一个方法解决了两个问题。  

LSTM的一个广为人知的优点是相较于传统的RNN，它可以解决梯度消失问题，这在吴恩达课程中也有提到过，我感觉这其实就是LSTM最大的优点和存在的意义，最初作者试图一次性全部训练，但是后来因为时间复杂度和计算负担的原因改成了后来被大家效仿的重叠frame的方式训练。  

## Experiment  

语料库中有29h的数据，18h用于训练，5.5h作为dev集，5.5h作为测试集，大致6:2:2分，比较科学，语料库选择的节目是法语频道的新闻、辩论和娱乐三个频道。数据进行了强制对齐和手动调整边界两步预处理，作者声称由于segmentation太粗糙，所以就不用测试集了，最终的结果是dev集的结果……之后又详细的介绍了一下特征提取、网络架构以及训练过程的参数，这里就不详细记录了，baselines采用BIC和Gaussian divergence，还有之前他们自己开发的TrisouNet。  

传统的SCD采用召回率和准确率作为评价指标，当检测的改变点位于实际改变点的可接受区间内视为预测成功，但是结果对这个区间的大小实在太过依赖了，当区间不断降低的时候准确率和召回率都会迅速的降低为0，这显然是非常不科学的，这也表明了以此作为标尺对标记员标记的准确性也有很大的依赖，因此不够准确。所以作者采用纯度purity和覆盖率coverage作为评价指标，它们对于区间的大小依赖性更低。purity和coverage是聚类分析的两个经典指标，在SCD的问题中也能够应用，coverage即预测片段和正确片段的最大覆盖率，而purity是正确片段数占预测片段数的比例。如果出现很多说话者改变都没有被检测出来，会表现为高purity但低coverage，这和准确率和召回率其实比较相似，只不过是用聚类里面的思想来表示而已。结果显示性能明显优于其他对照组，最高purity可以到达95.8%，高了其他0.7%的百分比，提升了表现的上限，这是由于传统的双窗口检测算法无法在一个窗口内有两次变化的时候全部将其检测出来。从purity和coverage的单一对比来看，作者的算法可以显著的提高两者的表现，例如在同等的purity下，该算法相比于BIC算法来说平均提升了coverage 19.5%。  

作者也试图将这一系统应用到说话人识别系统中，结果发现识别率并无显著上升，这可能是由于SR系统中的聚类部分仍然是应用了传统的距离比较方法来进行的，它们所需要的特征更应由传统的SCD部分来实现。此外作者还研究了样本不平均对整个效果的影响，结果显示当区间长度在150ms时效果最好，能达到95%，而就算没有区间的时候正确率也有70.6%，从而看出这个问题也没有想象的那么大。  

有趣的是，作者也搞不清楚为什么LSTM为什么有效，我们知道LSTM可以应用里面所有时间步的信息来进行处理和预测，作者试图将邻近frame的特征和当前的特征连接起来输入到LSTM里面，结果发现帮助并不大，因此说明LSTM内部的记忆机制已经足够强大到记忆和处理连续的文本信息。作者同时做了一个测试，看看在语音序列的什么位置表现最好，结果显示在中间部分，也就是Bi-LSTM得到了足够的信息时表现的最好，证明LSTM充分的利用了记忆功能，将每一个时间步输入的信息都应用了起来。  

## Conclusion  

总结一下，作者使用了Bi-LSTM网络处理SCD问题，以purity和coverage作为评价指标，得到的结果明显优于其他传统方法，并做实验证明了LSTM记忆功能的有效性，整篇文章对应图片和文字部分非常接近，不用跨页寻找，读起来非常舒服，这可能是因为所投的会议并无图片位置的严格要求所致。此外语句非常通顺，没有高深莫测或者偏门的词语使用，语言逻辑读起来也非常流畅，这可能是因为作者是中国人所致。整体来看，放到2017年这篇paper的idea的确足够有创新度，后续的paper也参照了该文章的idea进行后续的深入研究。  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
