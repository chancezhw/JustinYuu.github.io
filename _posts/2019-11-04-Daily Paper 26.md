---
layout: post
title: "Daily Paper 26"
description: "Notes"
categories: [MMML-Self_Supervised]
tags: [Paper]
redirect_from:
  - /2019/11/04/
---

# Daily Paper 26 - On Attention Modules for Audio-Visual Synchronization  

## Introduction  

因为昨天过周末没看论文，所以今天补上。这篇paper是之前multisensory那篇paper的改进版，主要改进是添加了注意力机制，文章貌似还没有发表，一直挂在arxiv上。这篇文章是UCF和Netflix合作的paper，一作是UCF的学生，在Netflix实习的时候搞出来的。这篇paper主要研究视听时序对齐(AVTS)任务中注意力机制发挥的作用。  

在人对视听对齐任务的判断中，人会更倾向于注意那些有辨别力的声音出现的部位，比如说话的嘴唇，而更不会去注意那些无差别的声音，比如BGM，因此作者也想通过注意力机制使得网络学习这一判别方法。作者用了巨长无比的篇幅来介绍了AVTS任务的背景和应用场景，以及详细的介绍了一下AVTS任务究竟为何物，由于AVTS之前介绍过了，这里就不再叙述了。作者训练了两个注意力模型，第一个是仅时序模型，第二个是时序+空间模型，同时作者使用软注意力机制，使得模型可以耦合多个差别性物体做出最终的结果判断，避免了逐个判断而产生的判别结果冲突。  

为了将时序注意力考虑在内，作者将每一个视频都分成了多个时序块，对于每一个时序块分别提取视听特征，在块内计算跨空间和时序域的全局池化特征。来自不同块的特征通过时序注意力模块中，在该模块里网络对每一个视频的时序块定义一个置信度分数，最终使用softmax输出所有的置信度分数，得到最后的结果。作者通过实验发现该模型拥有更高的分类准确率和更快的收敛率。  

作者紧接着研究了时空注意力机制对分类准确性的影响，在该模型中，网络不仅将整个视频分为多个时序块，还将每个时序块又分为多个空间块，和之前时序注意力机制的全局平均池化层相比，该网络将每一个时序块的空间特征直接放到权重模块中，计算每一个时序块中的每一个空间块的置信度分数，之后使用一个跨时空的softmax输出最终的结果，最终的特征用它们的加权平均来计算得出。  

总体来说，这篇paper中作者提出了一个基于注意力机制的框架，用自监督方式进行训练解决视听对齐问题。注意力模块通过学习来决定将其自身添加到哪一部分，以决定视听是否对齐。通过实验作者发现将时序注意力机制和时空注意力机制纳入网络中能够显著的提高分类的准确率，验证了注意力机制能够很好的选择视频当中的分歧部分。  

作者是第一个将注意力机制引入视听对齐任务中的，也自然而然的是第一个将注意力机制引入自监督学习的视听对齐任务中的，这里作者对注意力机制、自监督学习和视听对齐任务做了一些介绍，我就不详细复述了后面两个，主要说一下注意力机制。  

注意力机制已经在很多领域上有了广泛的应用，例如QA、VQA、MT、动作识别和机器人等，注意力机制主要分为硬注意力和软注意力两种。硬注意力方法的输出是基于每一个点是否被注意到这个二分采样确定的，这种方法一般需要attended points的ground truth，这是需要人类来手动标注的。第二种是软注意力机制，这也是之前比较火的一种，从给定的数据捕获point的重要程度，用概率分数的形式表现出来，从而达到给定的目标。软注意力机制可以使用可微的损失函数和数学操作，但是硬注意力机制可能无法获得连续的梯度，因此不可微。由于作者使用了可微分的损失函数，因此作者使用了软注意力机制，并使用该注意力网络提供了一个时空或者时序视频片段的概率图。  

## System  

作者提出的神经网络架构主要分为三个步骤：第一个步骤是提取特征，将输入的视频分成若干块，然后提取每一个块的时空特征；第二个步骤是计算时序和时空的注意力，评估了视频不同部分的的重要性；最后一步是将从视频中不同部分提取出的特征结合为一个基于所有特征的加权平均的全局视频特征中。作者使用了两个不同的注意力模型，接下来详细的介绍一下。  

首先是第一个步骤，重点在于时空特征的联合提取。作者将每一个时序块的长度设置为25帧，视频中的图像和声学特征分别独立提取，之后跨channel连接起来，之后通过5个卷积层，得到最终的联合表示。该联合表示随后输入到注意力模块中。  

注意力模块包含了两层1×1×1的卷积块，联合视听特征被导入这两层进行卷积操作，得到了每一个块下的标量置信度值，该置信度接下来被传到一个softmax函数中以得到一个对应每个块的权重，这些权重加权平均，就得到了整个视频的加权平均权重，这个最终的权重被传到决定层中。总体来讲，该注意力模型的作用是衡量视频中每一部分（块）的重要程度，从而帮助最终决定的产生。  

对于时序注意力模型，首先用全局平均池化来将输入的每一个块的特征平均池化为1×1×1×C的特征向量，之后将所有的特征向量通过三维1×1×1卷积核得到每一个时序块的置信度值，再将置信度值通过softmax函数，将最终的修正权重再重新应用到时序特征中，导入决定层中做出最终决定。对于时空注意力模型，作者将1×1×1卷积直接应用到最初的H×W×T×C模块中，得到了一系列展开的置信度值，通过softmax层后得到了展开的修正权重，然后将其整合为最终的概率，加权平均之后得到最终的1×1×1×C特征，应用到最终的决定层中。两者的区别在于前者的注意力模型直接忽略了时空特征，将空间的不同用全局平均池化隐藏了，而后者就是完全展开再进行卷积计算。  

作者进行比较的baseline很简单，由于要研究注意力机制的影响，那么baseline就是不加注意力机制的该模型，直接将加权平均权重输入到决定层中进行比较，略过注意力机制这一步。此外作者的决定层由两个FC层组成，分别是512和2维。  

## Experiments  

Dataset使用AudioSet，使用演讲类的数据来训练注意力模块，用generic impact sound类里面的数据来测该方法的鲁棒性。作者的负样本来自于同一视频的非对应位置。作者对该模型的性能进行了定量和定性的量化，具体如下。  

首先进行定量分析，结果显示在speech和generic sound测试集上时空注意力模型的效果都显著优于basline，略优于时序注意力机制，这表明时序注意力机制对分类的准确性的帮助更大，而空间注意力机制虽然也有一些帮助，但是帮助不大。此外通过置信度分数的分布图中可以看出注意力机制能够更好的区分正负样本，达到更好的分类效果。  

接下来进行定性分析，作者选了不同的时序块进行分析，对比其置信度分数，结果显示信息更多的、更有辨别力的时序块分数更高，这表明该注意力机制网络能够很好的判别视频过程中有辨别力的时序和区域。  

## Conclusion  

作者主要将注意力机制引入到了自监督学习的时序视听对齐任务中，结果显示注意力机制能够明显的提高模型在该任务下的表现。此外，作者还研究了两种不同的注意力机制的表现，结果显示考虑时间和空间特征的模型的表现会优于只考虑时间特征的注意力模型，但是具体的表现提升不是很多，这表明时序注意力对整个网络的提升更大。作者还希望使用其他架构，比如RNN来研究注意力机制对该任务的影响，此外作者还认为该架构能够很好的评估视听两模态的不匹配程度，期待后续对这一部分的研究、  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
