---
layout: post
title: "Daily Paper 14: YOLO"
description: "Notes"
categories: [CV-classic]
tags: [Paper]
redirect_from:
  - /2019/10/22/
---

# Daily Paper 14 - Yolo_You Only Look Once Unified,Real-Time Object Detection  

## Introduction  

今天读的paper是YOLO，一种非常经典的目标检测的算法。在之前，目标检测问题都会被当做成分类问题来处理，而这里作者将其看成分割边界框和连接类概率的回归问题。作者使用一个神经网络用一次估计来直接从原图像中判断边框和类概率。作者提出的模型速度非常快，YOLO模型可以在一秒内实时处理45帧，另一个较小的网络Fast YOLO可以在一秒内实时处理155帧并保持mAP是其他目标检测算法的两倍。与目前的检测系统相比，YOLO有更高的定位错误率，但是会有更少的false positive发生。最后，YOLO有很好的泛化能力，能够在其他领域的自然图像处理中有优于其他算法的表现。  

能够媲美人眼目标检测的机器学习算法是非常必要的，在自动驾驶、人工辅助设备、机器人等众多领域，实时检测都是必不可少的。在这篇paper发出之前，大家采用的目标检测算法都是通过对图像中的物体分类定位实现的，比如DPM，采用滑动窗口分别识别图片中的各个部分，或者R-CNN，采用region proposal方法生成潜在的边框，然后通过一个分类器对边框中的物体进行分类识别。这种方法速度非常慢，并且很难优化，因为每一个个体的组成部分都需要分别训练。  

而作者将目标检测问题看成了一个回归问题，将图像的原始像素和边框坐标和类概率直接对应起来，因此You Only Look Once就可以完成物体识别和定位两部分功能，所以该系统起名为YOLO。YOLO其实很简单，首先resize图像，然后用一个CNN处理，进行非最大抑制，将检测结果限制在置信区间内。这种方式相对于传统方式有三大优点：第一，快，在实际应用中可以达到在25微秒的延迟内完成处理；第二，YOLO采用整体的图像进行处理，那么相对于传统的滑动窗口来说，看到的信息就更为全面，因此可以获得更多原始信息；第三，YOLO可以学习到物体的可泛化的表示，从而具有高度的可泛化性。  

不过作者也承认，YOLO速度虽然快，但是准确率仍然距离主流的目标检测算法有差距，主要原因是它可以迅速准确的识别，但是无法准确的定位，特别是小物体。作者在后续的工作中会不断完善改进这一部分。  

## System  

接下来看YOLO的网络架构细节。YOLO将原始图片分成S×S的网格，如果物体的中心在某个网格中，那么那个网格就负责来检测该物体。每一个网格预测B个边框和这些边框的置信分数，置信度分数代表该边框内含有物体的可能性和边框内物体预测的准确度，表示为Pr(Object)\*IOU，其中Pr只有0和1之分。每一个边框内含有5个预测值：x,y,w,h和置信度，(x,y)代表坐标，w,h代表宽和高，置信度就是前面说的Pr\*IOU。此外，每一个网格也预测C个条件类概率，记作Pr(Class<sub>i</sub>\|Object)，一个网格只预测一个类的概率，不管有多少个边框B，最后将条件概率与前面的置信度分数乘起来，即得到了Pr(Class<sub>i</sub>)\*IOU的值，也就是特定类在每个边框的置信度。  

接下来是CNN的架构，卷积层用来提取特征，FC用来预测坐标和概率。YOLO使用的架构灵感来源于昨天介绍的GoogLeNet，网络共有24个卷积层后缀最大池化，2个FC层，不过并没有采取inception架构，而是使用了NIN模型中的3×3卷积层后缀1×1降维层。此外，作者还训练了一个Fast版本的YOLO，Fast YOLO共有9个卷积层，内部的filter数量也相应变少，所有的测试和训练的参数都和YOLO相同。  

作者现在ImageNet上进行卷积层的预训练，达到了ILSVRC12测试集上的88%准确率，预训练的层数只有20+1，预训练之后再将后面的4+1加起来，后加的这几层权重随机初始化。所有的非线性激活函数使用leaky ReLU，leaky参数为0.1，使用平方误差，不过虽然优化起来很简单，但是和我们最大化平均准确率的目标并不太吻合，它将定位误差和分类误差完全等同，但是这可能不太合适。此外，很多网格里面可能并不含有物体，置信度公式中得出的结果便为0，从而overpower那些真正含有物体的网格的梯度，从而导致训练有可能提前收敛。所以作者采用了增加边框坐标的预测损失，减少不含有物体的边框的置信预测损失来解决。此外，为了使大边框的小误差带来的影响比小边框要小，作者使用w和h平方差来代替直接使用w和h的值。  

YOLO可能会同时在每个网格中预测多个边框，这里作者选择IOU最高的那一个边框作为网格的对应边框，一个边框只对应一个网格。这使得每个边框的预测器都更为精细和专一化。  

训练一共进行了135轮，batch为64，momentum为0.9，衰减率为0.0005.使用dropout，概率为0.5，此外还进行了data augmentation，通过随机的缩放和平移增加了20%的图像。  

YOLO同时也存在一些局限性，比如对小的物体的识别效果不好，此外由于一个网格只能鉴别一个类，那么如果有两个不同的物体的中心同时位于一个网格中心，那么就很难进行检测。同时，由于YOLO的模型是从数据中学习的，所以碰到一些极端的或者不常见的状况会很难处理，YOLO使用的特征也相对来说比较粗糙，因为模型中使用了较多的下采样层。最后，由于训练的时候是用的通用的损失函数，所以小边框和大边框导致的损失值是相同的，在大边框中出现的小错误影响不大，但是在小边框中的小错误对IOU的影响就会很大，而作者发现他们的主要错误出在定位错误上，说明这带来的影响还是挺大的。  

## Experiments  

作者主要将YOLO的性能和其他的目标检测算法的性能做了一下对比，结果显示在VOC2007上的实时对比中YOLO的mAP最高，Fast YOLO第二，FPS(Frame per second)Fast YOLO最快，能达到155。非实时对比中YOLO的表现也很不错，66.4的mAP只比其他优秀的非实时目标检测算法少个位数。作者还给出了YOLO与Fast RCNN在各方面的识别误差比例，YOLO对背景内容的误判率（4.75%）比fast rcnn的误判率（13.6%）低很多。但是YOLO的定位准确率较差，占总误差比例的19.0%，而fast rcnn仅为8.6%。在VOC2012上，YOLO的mAP为57.9%，比当今的最高准确率略低，但是作者将Fast R-CNN和YOLO结合了起来，最后得到的结果优于其他检测方法。  

作者又测试了一下YOLO的泛化能力，用来判断艺术品中的人像检测，数据集采用Picasso Dataset和the People-Art Dataset，结果显示YOLO的泛化能力明显优于其他目标检测算法，其准确率和召回率均高于其他目标检测算法，其AP和Best F1值明显高于其他检测算法，generally，YOLO对非自然图像物体的检测率远远高于DPM和RCNN系列检测方法。  

## Conclusion  

总结一下，作者提出了一种新型的目标检测算法YOLO，YOLO的特点是指检测一次就可以同时得到物体的种类和位置，即将分类+回归问题改成分类问题，所以YOLO的检测速度会更快。此外作者还提出了一种更快的Fast YOLO，是目前最快的目标检测算法。YOLO还有良好的泛化性能，对非自然图像物体的检测率远高于其他检测算法，不过YOLO是一种以时间换精度的算法，其识别的准确率不如其他目标检测算法。  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
