---
layout: post
title: "Convolutional Neural Networks Chapter 4"
description: "Notes"
categories: [Convolutional-Neural-Networks]
tags: [Python]
redirect_from:
  - /2019/07/03/
---

# Convolutional Neural Networks Chapter 4  

本周是这一门课的第四周，也是最后一周，这一周主要介绍人脸识别，希望这周的课程能和上周一样干货众多。  

## Face Recognition  
首先是介绍了一下吴大大之前在百度时林元庆大佬实验室做的视频，百度入口并不需要工卡，而是通过人脸识别闸机自动识别。值得注意的是，如果用工卡或者图片的话，并不能识别出来，因此冒名顶替是不存在的，也就是说这个人脸识别系统具有活体检测功能，不过这并不是这一节所研究的。现在人脸识别已经在国内广泛的普及开来，两三年前还是比较新的应用现在已经到处可见，可以看出人脸识别近几年发展的火热。  
吴恩达教授首先介绍了人脸识别和人脸校验的区别。人脸校验只是简单的输出所给定的图片或者一个特定的人是不是所声称的那个人，我们称之为一对一问题，但是人脸识别相对而言复杂的多，因为其要对多个人进行分辨和识别，也就是所谓的一对多问题。举个例子：如果一个校验系统能够达到99%的校验率，看起来还不错，但是如果在人脸识别系统中，有100个人需要识别，那么如果对单个人的校验成功率仍然是99%的话，那么犯错的几率相对于单人校验系统就是100倍，因此对于多人的人脸识别系统，我们所需的正确率会更高。显然，人脸识别比人脸校验要复杂的多，应用也广的多。  
人脸识别的第一个挑战是One-shot learning，即从一个照片中就可以学习到该人的特征，并能从不同的图像中识别出这个人。那么自然而然我们会想到softmax，可是问题在于训练的样本实在是太少了，甚至少到一人只有一张照片，显然作为训练数据还是太少了，训练效果会很差，所以我们需要其他的方法来解决这个问题。解决问题的方式具体而讲，是让算法训练一个“相似性”函数("similarity" function)，用d(img1,img2)作为两张照片之间的差异度，并设置一个阈值τ，如果d<=τ，那么就可以认定这两张图片是一个人。这个方法在我的理解下，抛弃了以前让机器“记住”特征的想法，而是直接训练一个新的算法，从而让机器能够自动分辨出新的人和照片里的人是不是同一个人，也就是说教会了机器“分辨”的能力。那么d函数的实现需要通过一个称作“Siamese network”的网络实现。将人脸图片x1导入ConvNet，不用softmax，而是使用全连接层，得到的向量f(x1)，将其看做输入图片x1的编码（encoding）。在遇到新的图片的时候，运用相同的ConvNet对其进行同样的计算，然后直接对比f(x1)和f(x2)的编码，将差异度的计算转化为编码的计算，具体而言，将编码的L2范数取值定为d函数的取值，之后进行比较，差值越小表示越像同一个人，差值越大表示越不是同一个人。这种孪生架构的网络称之为Siamese network。这个思想来自一篇论文：[Taigman et al., 2014, DeepFace closing the gap to human level performance](https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf)。  
为了达到该目标，我们需要定义一种新的损失函数：Triple Loss，即三元损失。对每一种学习对象，也就是人脸，都要定义三种训练数据：Anchor,Positive,Negative,其中锚照片和正负例照片各组成一组，分别代表同一个人的图片和不同两个人的图片，那么显然训练的目标就是使d(A,P)<=d(A,N),也就是使f(A)-f(P)的二次范数小于f(A)-f(N)的二次范数，或者写成两个L2范数相减小于等于0。但是有种情况是所有的结果都是0的话，等式会恒成立，也就是f(x)=0是这个方程的平凡解。但是显然，使所有的网络输出值全为0会使得网络训练的结果退化，并无实际意义，而这样会使得网络训练的结果有可能向着这一方向发展，因此我们需要设置一个margin，也就是一个很小的正数来规避这种情况，从而使两个d之间必须有一定的差距才可以。那么最后总结一下，每组训练数据都需要A,N,P三个图片，也就是输入数据组成，因此该损失函数称为Triple Loss，损失函数写作L(A,P,N) = max(||f(A)-f(P)||²-||f(A)-f(N)||²+α,0)。训练的阶段需要用一个人的多张照片进行训练，不过这并不是训练机器记住这个人的面部特征，而是训练one-shot learning对不同人的脸能够有效的区分。在训练的时候，随机的选择APN会使得d(A,P)+α<=d(A,N)很轻易的被满足，这是由于随机选择照片的话，选到相同人的两张照片比不同人的两张照片概率小太多了，这就导致训练的结果鲁棒性不够。所以实际中要选择一些不那么容易，或者比较困难去训练的三元数据进行训练。由于这个领域的数据实在过于庞大，有时候甚至能够数以千万计或者数以亿计，因此吴恩达建议不要自己建立数据集，而是直接用别人的数据集。那么话又说回来，既然用了别人的数据集，也就没有必要训练别人的数据了，直接去下载别人训练好的网络和模型就好了，因此吴恩达最后还是建议直接参考别人的已经训练好的模型，直接应用到自己的项目里就好。  
除了triplet loss，还有一种训练Siamese Network参数的方法：Binary Classification。这个方法对于每个样本都训练两张图片，同样输出到Siamese Network中得到两个编码f(x1),f(x2)，但是不同的是它将两个编码通过sigmoid函数做了一个二分分类，如果是同一个人就输出1，不同就输出0。损失函数就和二分分类的激活函数输入的形式一样，也是wx+b，只不过x是两个编码的差值。也可以χ相似度公式，把(f(x1)-f(x2))²/(f(x1)+f(x2))当做x，然后把wx+b作为激活函数的输入，这两种激活函数的输入都是可以的。  
两种方法的形式不同，但是方式都是一样的，都应用了Siamese Network作为预测方式，并且在计算时并不需要缓存图片，只需要保存编码即可，这样降低了计算量，也减轻了存储的压力。  

## Neural Style Transfer  


---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
