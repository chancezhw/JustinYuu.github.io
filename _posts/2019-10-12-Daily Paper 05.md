---
layout: post
title: "Daily Paper 05"
description: "Notes"
categories: [Daily-Paper]
tags: [Paper]
redirect_from:
  - /2019/10/12/
---

# Daily Paper 05 -   Speaker Change Detection Using Features through A Neural Network Speaker Classifier  

## Introduction  

本来想这几天读几篇CV方向的经典文献的，结果突然来任务了，又多了两篇论文，那就再看一下。  

这篇是Interactive Intelligence公司在Intelligent Systems Conference 2017上发的一篇工程论文。从名称可以看出，这又是神经网络在SCD领域的一个分类，而根据摘要中的信息可以总结出，他们训练了一个神经网络分类器用于识别说话者，并探测说话者的改变，最终得到的结果是100%识别以及97%的hit rate，这个性能听起来也太牛x了。  

对于SCD问题来说作者将其分为两类，分别是retropective传统类型，以及更高要求的实时类型两种，前者一般用特定的检测算法和模型来训练，比如GMMs和HMMs等等，一般用BIC，KL等经典的量化方式来进行。而对于实时检测来说，难点是必须要通过有限的前置信息在可接受的短时间和短计算负担下内做出正确的检测，这也就使得其难度大大增加。很多学者也对实时检测的SCD进行了研究，这里我就不把研究都放上来了。  

这里作者提出了一个新系统，首先用一个前置神经网络来用原始的语音对话进行分类训练，然后通过0.5s,1s或者2s之间的相邻间隔的相似程度来判断是否发生了说话者的改变。在实际的测试中，虽然测试所使用的说话者有很多并不是训练集里已有的说话者，但是该系统仍然能够进行区分，这就使得作者可以利用该系统开发一些比较直接的距离metrics去捕捉说话者的改变，这个系统在TIMIT语料库作为数据集的表现很好，并与非神经网络的模型相比进步巨大。  

## Preparation  

作者开了一个section用来介绍数据的准备工作，这里使用了TIMIT语料库里的326名男性读者，而训练集里还有女性读者，以及有男性读者和女性读者的测试集在这里都不会使用到。对于每一个speaker来说，都会从3个类别中以5:3:2的比例选出10句话，分别称为SX，SI和SA，之后326名男性speaker会被分成200和126的两组。对于A组来说，在SX和SI类别的句子在不同的speaker之间是不同的，每个说话者的语句被组装成了大约有20秒钟的speech，作为神经网络分类器的训练集。SA中的句子是完全相同的，他们用来进行测试，所以需要消除所有可能会导致表现差异的变量。对于B组，speech是由不同的speaker读的语句拼接而成的，126个speaker的前一半，也就是前63个，会用SX和SI类别的句子组合成对话，他们的目的是为了找到SCD的最优阈值，而后面的63个也是用SX和SI拼接而成的句子，用来进行性能的测试，而由于其测试的内容正是之前寻找的阈值，所以数据集的组合方式必须完全一致，这里的实验数据组合还是相当科学的。  

在预处理阶段，要将最大的振幅scale为1，然后使用VAD把空白的部分给消灭掉，实验显示使用VAD处理过后表现会明显提升，特别是数据比较嘈杂的时候。这里使用了一个Giannakopoulo的算法来提高了VAD的性能，从而提升了VAD所捕获的音频部分的质量，具体的原理我也看不太懂，就不写了。这里的提取特征使用的是经典的MFCCs，使用了25ms的Hamming窗口，10s/hop，之后每个读者的数据将会各自均一化。此外，这些39维的MFCCs特征帧会连接起来，从而组成多个有重叠部分的更长的帧，这里大帧以10个小帧为单位组成，30ms/hop。  

## System  

接下来就是神经网络部分的架构了，总体来讲他们借鉴了吴恩达在机器学习这门课程中的建议……使用了将multi-class问题转变为K个二分问题的方式来解决，区别于一般的多分类问题的解决方式，即使用softmax和交叉熵损失函数，他们使用的是二元回归损失和分类函数，不过整体的区别也不是很大。这里还添加了正则项以解决overfitting的问题，整个神经网络只有1个隐藏层，是一个非常浅的神经网络，总体的规模是390:200:200，使用sigmoid作为激活函数，这里讲了一些很基础的反向传播的计算过程，就不详细记录了。最终会输出K维向量，使用一个argmax来找到对应的那一类，那么因为有多个帧，我们记为M，那么最终的结果就是由所有M个帧的对数和的形式得出，然后再用argmax取结果。如果M是1的话，那么最终的结果将完全取决于当前的帧，但是如果M是整个数据集的话，最终的结果将由整个数据集共同决定，那么显然M越大准确率越高，最终的实验结果表明M是整个数据集的时候，训练集和测试集的准确率都是100%，而当M是1的时候，测试集的正确率是79.65%。我们既然发现M只要足够大，总能够达到100%，但是我们又想尽可能的减少时间，那么我们就可以尝试一下实验或者计算得出准确率是100%的临界帧数，作者通过公式得出，在测试集中只需要11.59个帧就可以达到100%，时间是0.42s,这个时长还是比较短的。  

目前的神经网络的规模其实是经过实验得出的最优网络，其方式是通过建立grid进行实验，以1/10数据集规模的随机数据进行简单的训练，找出性能最好的网络结构。整个训练过程在两个循环过后准确率上升幅度不足0.1%的时候停止，所有的数据一批进入，200个speaker每个20s，i7CPU训练的情况下只需要1h，其实这么浅的网络训练起来肯定会很简单，训练成本其实不算大。  

## Experiment  



---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
