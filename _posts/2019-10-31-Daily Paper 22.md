---
layout: post
title: "Daily Paper 22"
description: "Notes"
categories: [MMML-Self Supervised]
tags: [Paper]
redirect_from:
  - /2019/10/31/
---

# Daily Paper 22 - Audio-Visual Scene Analysis with Self-Supervised Multisensory Features  

## Introduction  

今天的这篇paper是UCB在ECCV18上的paper，也是一篇自监督的视听场景分析的paper。作者使用一个融合的多场景表示来将一段视频的影像和音频联合建模，用自监督学习的方式来预测一段影像和一段音频是否是对齐的，其实也就是昨天看的AVTS问题。作者使用该训练好的模型进行了三个下游任务的应用，分别是1.音频源定位。2.视听动作识别。3.开/关音频源分离，比如在一段外文演讲中分离出翻译的音频。  

本文的主要贡献是：1.学习了一个融合了音频和视频信息的通用视频表示方式。2.定性（声源可视化）和定量（动作识别）的评价了该表示的有效性。3.提出一种新颖的当今唯一能够应用在真实场景下的视频条件源分离方法，该方法使用作者学习的表示来分离屏幕上和屏幕外的声音。  




---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
