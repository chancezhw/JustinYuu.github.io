---
layout: post
title: "Daily Paper 08"
description: "Notes"
categories: [CV-classic]
tags: [Paper]
redirect_from:
  - /2019/10/13/
---

# Daily Paper 07 - FaceNet A unified embedding for face recognition and clustering  

## Introduction  

今天读的paper是著名的FaceNet，这是谷歌发表在CVPR 2015的一篇著名的人脸检测算法。  

在当时的研究背景下，高效的实现人脸验证和识别仍然比较困难，而作者研究的FaceNet，能够直接学习从人脸图片到图片之间的欧式距离的映射，而距离本身直接与人脸的相似程度相关联。那么人脸识别、验证和聚类等任务就可以通过传统方式+FaceNet嵌入来实现。作者采取了使用卷积神经网络直接优化嵌入本身，而不是和之前的深度学习方法一样增加一个bottleneck层。此外，为了进行训练，作者使用通过在线triplet挖掘方法生成的大致对齐的匹配/不匹配面部triplet, 这种方法的优势是极大的缩减了面部识别的空间复杂度，他们的最优秀的识别表现中一张面部图片只需要128个比特。此外，在LFW数据集上其系统的准确率能够达到99.63%，在Youtube DB上能达到95.12%，误差率相交其他方法来说下降了30%。作者同时介绍了谐波嵌入的概念，以及一个谐波三元组损失，其描述了不同版本的人脸嵌入，从而能够让不同的网络直接应用。  

具体来讲，作者主要是学习了一个欧氏距离的Embedding，让每一个图片都生成一个特定的Embedding，而嵌入空间内的欧氏距离直接与人脸的相似性挂钩，从而使得多种人脸识别问题可以统一的被解决：人脸验证变成了两个embeddings之间的距离计算，人脸识别变成了K邻近分类问题，人脸聚类可以用k邻近或者层次聚类等方法进行。  

之前的人脸识别方法都是基于深度神经网络用一系列已知的人脸信息训练一个分类层，作为一个bottleneck层嵌入到网络中，用来识别训练集中的人脸。这种方法的缺点是它的间接性和低效率：由于只能识别训练过的，那么要想尽可能的识别更多的人脸，必须要尽可能的多训练一些人脸，但是每个人脸的表示尺寸非常大，有数千维之多，因此就陷入了困境。虽然有学者用PCA对其降维，但是PCA本身是一个线性的变换，可以更好的用一层网络作为替代。  

相较于传统方式，FaceNet直接用triplet损失函数将其输出训练成128维的embedding，triplet损失函数在之后被广泛使用，不过这篇paper率先提出了这一算法。triplet中含有三个缩略图，分别是两个相同人的人脸图像和一个不同的人脸图像，通过用一个人脸图像和正样本与负样本的对比，从而通过一个距离差值来区分开相似和不同的人脸图像。而triplet的选择是得到优秀表现的一个关键，受到一篇叫做“课程学习curriculum learning”的启发，作者开发了一套新的负样本反例挖掘策略，从而使得在训练的过程中triplet的训练难度不断的增加，同时为了增加聚类的准确性，作者还研究了一套hard-positive的挖掘设备，使得同一个人的embeddings聚类更容易。从作者给出的图片来看效果还是比较好的，在其他系统中很难区分出来的相似图片能够很好的在FaceNet中得到区分。  

## System  

作者采用了两种深度学习网络架构，第一种是Zeiler&Fergus的架构，另一种是Inception的架构。作者不止一次的提到，其目的是为了得到一个直接的、端到端的学习方式，即采取triplet的形式，其输出直接反应了我们想在人脸验证、识别、聚类中得到的结果，也就是说作者试图得到一个embedding f(x)，这个embedding从图像x到特征空间R<sup>d</sup>，使有相同身份的人脸距离很小，而不同的人脸距离很大。作者同样认为triplet更适合人脸验证，因为其他方法希望让所有相同人的人脸图像投影到同一个位置上，而triplet只是希望让他们的差值在一个margin以内，因此提高了算法的容错率的同时还有很好的辨别能力。  

首先来详解triplet，triplet将输入的图片x嵌入到了d维的欧几里得空间内，作者对里面的数据施加约束，使得所有的投影都在一个d维的超球中，即所有点距离中心的欧氏距离都小于等于1，之后应用k邻近的思想保证所有的positive距离anchor的距离都小于negative距离anchor的距离，并且需要小到一定的程度，我们用α来表示这个差距margin，那么损失函数显而易见就是两个距离的差值+α，有点类似SVM。triplet有趣的地方在于你不能选的太简单，不然在训练的时候这些triplet就会打假赛，导致网络训练时loss收敛的速度很慢，因此我们需要选择一些难的triplet从而更新我们的网络权重。  

那么如何选择难的triplet呢？首先我们肯定能想到，要训练肯定不能一直选距离小于1的，那和没训练一样，所以一定要比距离1大，而且要尽可能大，同时和负样本的距离要尽可能小，然后找到argmin和argmax，即x的序号。但是我们知道，从y来寻找x是非线性的，因此时间复杂性可能会很高，并且错误标注的图片可能会占据距离差距最大的几个，因此我们找了半天找出来的很有可能是错误的，那么作者提出了两个方案来解决这个问题：1.每n步离线生成triplet，使用最近检查点的几个数据然后计算该子集的argmin和argmax；2.在线生成triplet，从一个mini-batch中找到argmax和argmin。我实在没看明白这两种有啥区别，但是可以看出采取了妥协的折中方案，不能一次进行就分批次进行，尽量找一些比较难的triplet。这里作者使用的是在线使用比较大的mini-batch，大概有几千个样本，计算其中的argmin和argmax。作者也尝试了离线生成的方法，这种方法的batch会小一些，但是最后的结论却是inconclusive的。不过这只是对于最大的positive距离而言的，而对于最大的negative距离，仍然是找出了最大的那一个，但是实际过程中却会出现模型崩塌的问题，即找出的最小值为0，这是无意义的，这个时候作者采用了一种选取semi-hard的负样本的方式来解决，具体做法是选择那些anchor与其距离与anchor与正样本的距离之差在margin α以内的样本，由于我们选的正样本本身就与anchor距离尽可能大了，因此比这个距离还要大，那么就说明差距也比较大了，同时在一定的距离以内又保证了其不会太过离谱，简而言之也就是给他设定了一个上界和下界。  

其次来看神经网络。训练过程使用SGD和标准反向传播，以及AdaGrad优化算法。依照惯例具体的参数设置就不写了，训练在cpu上共持续了1000到2000h，在训练的500h后，loss骤降，准确率突然提升，不过后续的训练还是会显著的提高表现，α设置为0.2。由于不同的应用场景可能会有不同的最优网络架构，因此作者选择了两种仅供参考，两种在上面也提到过了，第一种在传统的Z&F层中添加了一个1×1×d的一维卷积层，使得网络共有22层深，第二种使用的是GoogLeNet的Inception形式，而第二种是用来设计在手机上使用的，因此大幅削减了参数的规模，为了减少输入的尺寸，在高层不使用5×5卷积，从而降低了感受野的尺寸，但是结果显示性能并没有降低多少，因此并不会因为这个改变影响最终的性能表现。  

评估的metric使用的是VAL和FAR，VAL即正确识别为相同的占实际人脸相同样本的百分比，FAR即错误识别为相同的样本占实际人脸不同样本的百分比。数据集使用的是LFW和YouTube Faces DB。  

## Experiments  

这一部分就简要的写一下结果。s



---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
