---
layout: post
title: "Daily Paper 09: AlexNet"
description: "Notes"
categories: [CV-classic]
tags: [Paper]
redirect_from:
  - /2019/10/16/
---

# Daily Paper 09 - ImageNet classification with deep convolutional neural networks  

## Introduction  

这篇文章在经典款中也算是老的了，作者是Hinton手下的Alex Krizhevsky，他提出了AlexNet，将ImageNet LSVRC-2010比赛中的120万张高分辨率图像分为1000个不同的类别。在测试数据上，取得了37.5％和17.0％的前1和前5的错误率。Alexnet共有5个卷积-池化层和三个FC层，以及一个softmax层，使用非饱和神经元和GPU进行训练，并使用了dropout，在ILSVRC-2012上取得了很好的成绩，前五名测试失误率15.3%，远低于第二名的26.2%。  

这篇论文中使用的方法现在看来可能非常简单和基础，但是要知道在当时可谓是开创性的工作。在当时，大家普遍使用的数据集规模都比较小，因此这些数据集只能用来解决一些简单的问题，但是对于一些比较复杂的问题而言，小数据集是不够的，因此大家又去收集了一些规模较大的数据集，比如LabelMe和ImageNet。此外仅仅依靠大数据集还是不够的，他们还应用了效果显著的新型网络——卷积神经网络（...）来进行了建模和训练，并得到了很好的效果。此外CNN虽然效果很好，但是其代价高昂，因此作者采取了GPU训练的方式来进行训练，大大提高了训练的效率。  

这篇文章的具体贡献如下：使用ImageNet子集训练了一个目前为止最大的卷积神经网络，并得到了目前最好的表现。此外，作者写了一个高度优化的2D卷积的GPU实现，从而提高网络的性能并缩短了训练的时间，此外还有一系列方式来避免遗留的过拟合问题。而目前为止GPU的表现仍然不够强力，如果有更大规模的数据集和更好的GPU，表现会更好。  

从这个Introduction可以看出这篇文章是多么古老……所以这里我就简要的节选一部分重要的内容，不详细记录了。  

## Dataset  

Dataset使用的是ILSVRC-2010，这个数据集本身就是ImageNet的一个子集，用于2010年的ILSVRC比赛。在ImageNet上，习惯使用Top1和Top5错误率来评价性能，即第一个结果是不是目标结果，以及前五个结果有没有目标结果。ImageNet的图像尺寸是不同的，因此作者将所有的数据均下采样到256×256的固定分辨率，具体方式是先将短边缩小到256，再节选长边的中间部分。  

## Architecture  

网络的结构其实很简单，八个层，五个卷积层，三个FC层。以下是这个网络结构中比较新颖的部分，重要程度递减。  

ReLU的使用，使用ReLU作为激活函数训练的速度会比tanh快好几倍。在多个GPU上并行训练，同时使GPU只在某些层间进行通信。局部响应归一化，其实现了一种模仿真实神经元的横向抑制，从而在使用不同内核的神经元之间产生了较大的竞争，有助于泛化。重叠池化，一般的池化是由一些间隔为s个像素的池化单元组成的网格，每一个都代表了池化单元为中心的z×z的邻域。为了将整个原输入覆盖，一般s=z，但是重叠池化的s<z，在这里s=2，z=3，这种方法减小了top1和top5的误差，并使得网络的训练更不容易过拟合。  

最后再总结一下整体结构，八个层，前五个是卷积层，后三个是FC层，最后接一个1000维的softmax。第二、第四和第五个卷积层的内核仅与上一层存放在同一GPU的内核映射相连，第三个卷积层链接到第二层中所有的内核映射。全连接层中的神经元连接到前一层中的所有神经元。响应归一化层紧接着第一个和第二个卷积层。最大池化层，后面连接响应归一化层以及第五个卷积层。将ReLU应用于每个卷积层和全连接层的输出。  

## Reduce Overfitting  

接下来采取一系列措施减少过拟合，具体如下。  

1.数据增强  

减少过拟合最常用的方法就是标签保留转换(label-preserving transformations)，使用CPU进行转换，从而可以和GPU串行运行，因次数据增强本身可以看做不占用任何额外的训练时间。具体的增强方式有两种，第一种是平移图像和水平映射，从256×256中选出224×224，从而使得训练集的规模增加了2048倍。第二种是改变灰度，具体来讲就是对RGB像素值使用PCA，对每个图像的RGB通道添加由PCA找到的主成分，大小与相应的特征值成比例，再乘以一个来自均值0标准差0.1的高斯分布的随机值，这个方案将top1误差降低了1%以上，作用还是很大的。  

2.Dropout  

Dropout大家都很熟悉，即随机舍弃一部分神经元，从而降低整个网络对某些神经元的依赖性，进而提升网络的表现。这里的概率设置为0.5，即每一步都有50%的神经元失效，应用dropout后迭代次数相较以前翻倍，即训练时间增加，相应的过拟合程度也就得到了减少。  

## Details of Learning  

这部分是一些训练的细节，使用随机梯度下降法来训练我们的模型，每个batch有128个样本，动量（momentum）为0.9，权重衰减（weight decay）为0.0005。作者使用标准差为0.01、均值为0的高斯分布来初始化各层的权重。我们使用常数1来初始化了网络中的第二个、第四个和第五个卷积层以及全连接层中的隐含层中的所有偏置参数。这种初始化权重的方法通过向ReLU提供了正的输入，来加速前期的训练。作者使用常数0来初始化剩余层中的偏置参数。  

此外，作者对所有层都使用相同的学习率，在训练过程中又手动进行了调整，遵循的启发式方法是：以当前的学习速率训练，验证集上的错误率停止降低时，将学习速率除以10。学习率初始时设为0.01，并且在终止前减少3次。作者使用120万张图像的训练集对网络进行了大约90次迭代的训练，这在两块NVIDIA GTX 580 3GB GPU上花费了大约5到6天的时间，可以看出当时的GPU还是很弱的。  

## Results  

结果显示该系统在ILSVRC-2010上top5和top1错误率分别是17.0%和37.5%，第二名是25.7%和45.7%，可见虽然现在看起来准确率很低，但是在当时还是提高了很多的。在ILSVRC-2012上的top5错误率最好能达到15.3%，而其他模型只能达到26.2%。  

接着作者对网络的性能进行了定性的评估，结果显示识别效果很好，很多在图像边缘的物体也能够被准确的识别出来，大部分top-5的标签都非常合理。作者还提出了另外一个研究可视化网络的方法，即在最后一个FC层的输出4096维向量进行欧氏距离的比较，如果两幅图像的欧氏距离较小，即可以判定为相似，但是这种方式效率并不高，作者考虑采用自编码器的方式将欧氏距离转换为二进制编码，从而更快的完成检测。作者认为这种方式应该能更高效的判断相似图像，因为少了分类的环节使得图像的语义检测任务被取消了，取而代之的是直接观察两个图像本身是否相同，这样更能关注到图像的细节本身。  

## Discussion  

作者经过研究表明，一个大的深层卷积神经网络能够在纯粹使用监督学习的情况下，在极具挑战性的数据集上实现破纪录的结果。值得注意的是，如果移除任何一个卷积层，网络的性能就会下降。例如，删除任何中间层的结果会导致网络性能的top-1错误率下降2%。因此网络的深度对于网络的表现来说至关重要。  

为了简化实验，作者并没有使用任何无监督的预训练方法，尽管这样可能会有所帮助，特别是如果获得了足够的计算能力来显著地增加网络的大小而不会相应地增加已标记数据的数量。到目前为止，作者获得的结果已经获得了足够的进步，因为网络更大，并且训练了更长时间。但仍然有很大的空间去优化网络，使之能够像人类的视觉系统一样进行感知。最后，作者希望对视频也能够使用非常大的深度卷积神经网路，其中时间序列结构提供了非常有用的信息，这些信息往往在静态图像中丢失了，或者说不太明显，这可能是一种新的研究方向。  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
