---
layout: post
title: "Daily Paper 38: MesoNet"
description: "Notes"
categories: [MMML-DeepFake]
tags: [Paper]
redirect_from:
  - /2019/11/24/
---

# Daily Paper 38 - MesoNet: a Compact Facial Video Forgery Detection Network  

## Introduction  

今天的paper是MesoNet，一个检测面部虚假视频的网络。这里靶子主要是DeepFake和Face2Face这两个虚假视频生成方法。传统的图像检测方法可能对虚假视频的检测来说并不适用。因此，这篇paper抓鱼哦使用了深度学习方法，给出了两个层数较少的网络来研究图像的介观属性。作者用了一个词“mesoscopic”，意为微观和宏观的中间部分。作者在现有的数据集和自创的一个数据集上进行了测试，得到了超过98%的Deepfake检测率和95%的Face2Face检测率。  

## Former Knowledge  

### Deepfake  

这里介绍一下两种虚假视频的制造方法。首先看Deepfake，Deepfake出现在2017年，用于成人视频的换脸，并没有论文发表，毕竟没人想自毁名声。  

Deepfake主流的训练方法是是是使用两个自编码器来并行训练。encoder的作用主要是降维，decoder用来生成一个approximated dataset，encoder是共享的。训练和优化是通过计算两个decoder结果的L2距离来判定的。具体的生成方式是通过收集两个不同的人脸图像A和B，然后通过训练一个自编码器Ea来从A脸图像的数据库中重建A的人脸，然后用另一个自编码器Eb来从B脸图像的数据库中重建B的脸，两个自编码器共享权重，解码器相分离。当训练和优化结束后，任何一个含有A脸的图像就可以通过共享的编码器来编码，然后通过Eb解码器解码成B人脸，从而达到换脸的效果。  

在实际操作中，只需要将目标视频中每一帧的目标人脸提取和对齐，使用特定的自编码器来生成另一个有相同光照和表情的另一个人脸，然后将其融合到原视频中，达到换脸的效果。  

幸运的是，这种技术远非完美无缺。人脸提取和重新整合可能会失败，特别是在面部遮挡的情况下：某些框架最终可能没有面部重现，或者出现较大的模糊区域或面部轮廓加倍，但是使用更高级的网络可以轻松避免这些技术错误。更深入地讲，对于其他应用也是如此，由于在有限的编码空间上对输入数据进行压缩，自动编码器往往无法很好地重建精细细节，因此结果常常显得有些模糊。较大的编码空间无法正常工作，因为尽管可以肯定更好地细化了细节，但生成的人脸却趋于与输入人脸相似，因此失去了真实感，即形态数据传递到了解码器，这个后果是不希望看到的。  

### Face2Face  

Face2Face是由Thies等人研发的一种Reenactment重建型方法，主要是从一个目标面部表情中提取该面部表情，然后转移到另一张图片上。该系统需要预先录制一些目标人脸的视频来建立该人脸的模型，然后在运行的时候程序同时追踪源人脸和目标人脸的视频，通过在目标人脸上进行面部形状混合和扭曲，从而生成最终的人脸。  

## Proposed method  

作者提出的方法就是有效检测通过Deepfake和Face2Face模型生成的虚假视频的模型，由于换脸视频方式的大同小异，作者的一套模型可以有效的解决这两套换脸方法。简单来看，作者的方法就是从介观角度来分析换脸视频，而介观分析主要着眼于视频中的图像噪声，或者更高级别的眨眼。作者做了一大堆实验，跑出来了两个效果最好的框架。  

### Meso-4  

第一个网络叫做Meso-4，作者的整体思路是从复杂的网络开始，先找到效果最好的，然后再逐步压缩网络，直至网络层数又少，效果又不会降低，才是最优解。该网络的架构主要是由4个含有Conv+ReLU+BN+MaxPool四层的堆叠层组成，然后经过两个Dropout+FC层，最后通过一个sigmoid分类器输出最终的结论。  

### MesoInception-4  

第二个网络叫做MesoInception-4，这个名字就太好理解了，无非是上一个网络用Inception来替代，事实也正是如此，将前两个卷积层替换成了inception模块，只不过将Inception中的5×5改成了3×3。  

## Experiments    

这部分补充了一些实验的细节和结论。由于当时没有现成的数据集可供使用，所以作者自己做了一个数据集，使用上面介绍的方法分别创建了Deepfake数据集和Face2Face数据集。最后的结果显示Meso-4和MesoInception-4的分类准确率能在deepfake数据集上达到89.1%和91.7%，在Face2Face的准确率能达到level 0的94.6%和96.8%，在level23能达到92.4%和93.4%，在level40能够达到83.2%和81.3%。使用Inception的升级版Xception的时候，准确率能够达到compression level 0的96.1%和level 23的93.5%。  

作者还将image aggregation图像聚合添加到了网络测试中，结果聚合分数Meso-4和MesoInception-4在Deepfake和Face2Face能够达到96.9%，98.4%和95.3%,95.3%.  

作者还试图了解那些网络如何解决分类问题。这可以通过解释来完成卷积核和神经元的权重。作为图像描述符。例如，权重为正，负号为负，然后为正号的序列可以解释为离散的二阶导数。但是，这仅与第一层有关，而对于面部来说并没有多大意义。另一种方法是生成使特定滤波器的激活最大化的输入图像，以查看其对哪种信号做出反应。简而言之，如果注意到第i层和xa随机图像的滤波器j的输出，并在输入上添加正则化以减少噪声，则该思想归结为E（x）= fij（x）-λkxkp的最大值。  

作者认为可以根据应用于输出的权重的符号来分离这些神经元，以进行最终的分类决策，从而说明它们的激活是朝着对应于伪造类别的负分数还是对真实类别是正分数。令人惊讶的是，正加权神经元激活显示的图像具有高度详细的眼睛，鼻子和嘴巴区域，而负加权神经元激活的背景部分显示出很强的细节，从而留下了光滑的脸部区域。这是可以理解的，因为与未触摸的其余图像相比，由Deepfake生成的脸部往往模糊不清，或者至少缺少细节。  

作者认为还可以获取一批真实图像和伪造图像的平均输出层，观察激活的差异并解释输入图像中在分类中起关键作用的部分。如果在Deepfake数据集上研究训练有素的MesoInception-4网络，则眼睛会强烈激活真实图像，但不会激活背景为Deepfake的图像，但是Deepfake的图像显示了最高峰，所以可以推测这又是一个模糊的问题：眼睛是真实图像中最详细的部分，而眼睛则是伪造图像中的背景，这是因为面部经过了缩小处理。  

## Conclusion  

总结一下，作者提出了两个网络架构，有效的识别了Deepfake和Face2Face两种方法生成的虚假视频，此外作者还通过可视化分析了比较重要的介观部分：眼睛和嘴巴，认为针对这两个部分进行研究能够进一步提升虚假视频的识别能力。  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
