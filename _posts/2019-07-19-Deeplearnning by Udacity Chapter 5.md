---
layout: post
title: "Deeplearning by Udacity Chapter 5"
description: "Notes"
categories: [Deeplearning-by-Udacity]
tags: [Python]
redirect_from:
  - /2019/07/19/
---

# Deeplearning by Udacity Chapter 5  

这一章是这门课的最后一章，主要介绍RNN。  

对于文字识别领域来说，我们会遇到两大问题：首先，一些很不常见的单词，可能我们平时都没怎么见过，要让机器能够正确识别，有一定的难度；其次，有些近义词或者同义词长得很不一样，这就需要在神经网络中建立某种联系从而解决这个问题。  

这时候我们就要借鉴无监督学习的思想，具体做法是采用“词嵌入”，将不同的词语嵌入到多维的向量空间中，让语义相近的单词靠的尽可能近一点，语义相反的单词远一些。那么词嵌入的模型就是word2vec，那么如果想让三维的向量变成二维的，那么用机器学习中的PCA会丢掉太多的信息，并且效果也不好，所以可以用t-SNE来保持向量的相对距离不变。此外这里还介绍了一个比较有用的方法，叫做sample softmax，与普通的softmax相比，它将结果为0的一部分结果舍去，只采样一部分，并保留结果为1的所有值，从而降低输出向量的规模。  




---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
