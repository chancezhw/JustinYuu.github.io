---
layout: post
title: "Machine Learning by Andrew Ng Chapter 11"
description: "Notes"
categories: [Machine-Learning-by-Andrew-Ng]
tags: [Octave]
redirect_from:
  - /2019/02/09/
---
# Machine Learning by Andrew Ng Chapter 11
 
## 前言  
这章是最后一章了，本章主要介绍照片OCR，这章没有官方笔记，我会在博客里记的详细一点。  

## Problem Description and Pipeline  
照片OCR是指照片光学字符识别，简单来讲，就是从照片中识别字符并转录。其实OCR非常常见，比如我们使用扫描仪所用的OCR软件。  
接下来介绍了OCR的几个步骤，首先要识别检测文本，然后对文本中的字符进行分割，最后进行字符的分类和自动更正，这整个流程也称为照片OCR流水线(pipeline)。
![11-1](/images/Machine-Learning-by-Andrew-Ng/11-1.png)  
好冷的冷笑话..

## Sliding Windows  
滑动窗是一种应用在OCR流水线上的分类器。简单来讲，滑动窗的步骤有三步：第一步，进行监督分类学习，给予机器若干份指定大小的图片作为训练集，让其识别训练；第二步，将待识别的图片以上一步指定的大小进行滑动，步幅可以自己指定，然后判断每个图片内是否含有行人；第三步，扩大指定的尺寸，选取图片的相应部分，然后缩小到第二步指定的尺寸，接下来重复第二步的步骤，继续识别。  

## Getting Lots of Data and Artificial Data  
本节介绍的是人工数据，通过人工合成一系列数据可以从理论上获得无限量的训练集可供训练。具体来讲，通过给字符更换字体，对图像进行人工模糊、扭曲、变形，对音频加噪音等额外干扰。值得注意的是，加入的这一系列干扰项必须在真实数据组成的训练集中出现过。  
同时Andrew也提到，人工合成数据也不是毫无成本的，因此需要在人工合成数据前进行一下成本与收益的计算，考虑一下是否值得花费人工合成数据。  
我在看完这一节的课程之后产生了一些疑问，比较困扰我的一点是，理论上来说扩充的数据集所含有的特征必须是在真实的数据集中出现过的，那么所谓的人工数据只不过是将不同特征进行重新组合和拼接，那么如果测试集中出现了新的特征还是无法预测到，那么换言之只有将全部特征都在原始数据集中出现过才有效果。那么问题又来了，如果原始的数据集中所有特征都出现过，那么仅靠原始的数据集能否训练出理想的结果呢？如果不能的话加入这些重复特征的数据对测试结果能有多少提升呢？如果确实需要，是否需要扩充10倍这么大的数据吗？言而总之，我所理解的人工数据还是跳脱不了已有数据集的局限性，如果有新的特征或者新的相关性存在，依靠人工数据来扩充训练集我感觉效果貌似并没有想象中的那么好。  

## Ceiling Analysis:What Part of the Pipeline to Work on Next  
最后一节介绍的是上限分析。很好理解，自己设计的系统预测正确率肯定不会总是100%，那么一定在流水线的某一步成功率过低，为了检测到底哪一步有最大的提升空间，我们可以采取控制变量法，将要检测的那一项用完全正确的测试集代替，观察正确率，如此检测每一项，如果某一项改成完全正确后总体的正确率最高，那么就是这一项问题最大。也可以逐级累加，假设最初正确率是60%，将一项变成完全正确后正确率到了75%，再操作一项后变成80%，最后操作一项后到了100%，即最完美的情形。那么问题最大的一项便是最后操作的那一项，因为可以提高20%的正确率，所以应该着重改良流水线的最后一项。  
另举一栗，将脸部识别系统分成五官的识别系统，通过将正确的测试集结果代替原有的预测结果，得到提升的正确率，最后达到100%，观察操作哪一项的过程中正确率提升最多，那么就应该着重改良哪一项。  

## Conclusion  
Conclusion是最后一节的标题，也是我自己对于这门课程的总结。11周的课程，1月22日-2月9日，大概用了三周的时间学习完毕。通过这些天的学习，我对于监督学习、无监督学习都有了基本的了解，也对这些经典的算法进行了重新实现。此外，Andrew还介绍了一系列评判算法性能的方法，以及一些在项目进行中确定下一步应该做什么的判断方式，这在真正的项目实践中都是不可多得的宝贵指导。此外，所有的代码都通过Octave实现，这也让我重新温习了一下Octave/Matlab的语法。  
至此所有的内容都已经学习完了，所有的测试和编程练习我都拿了满分，还是有点小骄傲的：)  
![conclusion-2](/images/Machine-Learning-by-Andrew-Ng/conclusion-2.png)  

## foreward  
接下来我的主要工作是准备考研复试的上机考试，由于报了3月初的PAT-A，所以通过刷pat-a的题目来同时复习这两个考试，希望在考试之前能够将题目刷完。  
此外，我将在下周一开始进行下一门课程的学习，下一系列的课程是deeplearning.ai开设的，主讲人还是吴恩达大大，这次我申请了Coursera助学金，能够拿到最后的证明。这一系列共有5门课程，我将要学习的是第一门“Neural Networks and Deep Learning”，由于同时进行PAT的练习，更新的速度将会放缓，学习的内容还很长，要加油啦。  
![conclusion-1](/images/Machine-Learning-by-Andrew-Ng/conclusion-1.png)  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。
