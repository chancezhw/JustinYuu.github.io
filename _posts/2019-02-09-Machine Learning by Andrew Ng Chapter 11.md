---
layout: post
title: "Machine Learning by Andrew Ng Chapter 11"
description: "Notes"
categories: [Machine-Learning-by-Andrew-Ng]
tags: [Octave]
redirect_from:
  - /2019/02/09/
---
# Machine Learning by Andrew Ng Chapter 11
 
## 前言  
这章是最后一章了，本章主要介绍照片OCR，这章没有官方笔记，我会在博客里记的详细一点。  

## Problem Description and Pipeline  
照片OCR是指照片光学字符识别，简单来讲，就是从照片中识别字符并转录。其实OCR非常常见，比如我们使用扫描仪所用的OCR软件。  
接下来介绍了OCR的几个步骤，首先要识别检测文本，然后对文本中的字符进行分割，最后进行字符的分类和自动更正，这整个流程也称为照片OCR流水线(pipeline)。
![11-1](/images/Machine-Learning-by-Andrew-Ng/11-1.png)  
好冷的冷笑话..

## Sliding Windows  
滑动窗是一种应用在OCR流水线上的分类器。简单来讲，滑动窗的步骤有三步：第一步，进行监督分类学习，给予机器若干份指定大小的图片作为训练集，让其识别训练；第二步，将待识别的图片以上一步指定的大小进行滑动，步幅可以自己指定，然后判断每个图片内是否含有行人；第三步，扩大指定的尺寸，选取图片的相应部分，然后缩小到第二步指定的尺寸，接下来重复第二步的步骤，继续识别。  

## Getting Lots of Data and Artificial Data  
本节介绍的是人工数据，通过人工合成一系列数据可以从理论上获得无限量的训练集可供训练。具体来讲，通过给字符更换字体，对图像进行人工模糊、扭曲、变形，对音频加噪音等额外干扰。值得注意的是，加入的这一系列干扰项必须在真实数据组成的训练集中出现过。  
同时Andrew也提到，人工合成数据也不是毫无成本的，因此需要在人工合成数据前进行一下成本与收益的计算，考虑一下是否值得花费人工合成数据。  
我在看完这一节的课程之后产生了一些疑问，比较困扰我的一点是，理论上来说扩充的数据集所含有的特征必须是在真实的数据集中出现过的，那么所谓的人工数据只不过是将不同特征进行重新组合和拼接，那么如果测试集中出现了新的特征还是无法预测到，那么换言之只有将全部特征都在原始数据集中出现过才有效果。那么问题又来了，如果原始的数据集中所有特征都出现过，那么仅靠原始的数据集能否训练出理想的结果呢？如果不能的话加入这些重复特征的数据对测试结果能有多少提升呢？如果确实需要，是否需要扩充10倍这么大的数据吗？言而总之，我所理解的人工数据还是跳脱不了已有数据集的局限性，如果有新的特征或者新的相关性存在，依靠人工数据来扩充训练集我感觉效果貌似并没有想象中的那么好。  

## Ceiling Analysis:What Part of the Pipeline to Work on Next  
最后一节介绍的是上限分析。很好理解，自己设计的系统预测正确率肯定不会总是100%，那么一定在流水线的某一步成功率过低，为了检测到底哪一步有最大的提升空间，我们可以采取控制变量法，将要检测的那一项用完全正确的测试集代替，观察正确率，如此检测每一项，如果某一项改成完全正确后总体的正确率最高，那么就是这一项问题最大。也可以逐级累加，假设最初正确率是60%，将一项变成完全正确后正确率到了75%，再操作一项后变成80%，最后操作一项后到了100%，即最完美的情形。那么问题最大的一项便是最后操作的那一项，因为可以提高20%的正确率，所以应该着重改良流水线的最后一项。  
另举一栗，将脸部识别系统分成五官的识别系统，通过将正确的测试集结果代替原有的预测结果，得到提升的正确率，最后达到100%，观察操作哪一项的过程中正确率提升最多，那么就应该着重改良哪一项。  


---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。
