---
layout: post
title: "Daily Paper 03"
description: "Notes"
categories: [Daily Paper]
tags: [Paper]
redirect_from:
  - /2019/10/10/
---

# Daily Paper 03 - Pre-training of Speaker Embeddings for Low-latency Speaker Change Detection in Broadcast News  

## Introduction  

这篇paper是UIUC和IBM Research AI共同发表在ICASSP 2019的，主要研究低延迟SCD的扬声器嵌入物的预训练。从摘要中可以大题看出，作者使用了Siamese network的思想训练了一个神经网络，通过该网络生成嵌入物，从而应用在很多系统中。  

看了几篇论文，对SCD也算有了一定的了解了，所以这里就多写一下。传统的SCD方式就是使用距离计算的方法，使用滑动窗口来提取特征，然后使用某种距离来计算连续窗口的特征；另一种方法是使用模型来预测，用讲话者改变前后的片段和整体来fit这个模型，然后根据模型预测的分数来决定是否发生了变化，比如用BIC或者高斯似然分数，daily paper01就是用的这种方法。  

那么不管怎样，我们都需要用某种方法来提取语音的特征，常用的方法有几种，首先是i-vector，之前也介绍过，i-vector的表现总体来讲很好，但是其缺点是对于短时长的语音片段提取的效果不好，那么大家一般用BIC，高斯散度或者x均值等对短片段聚类，然后再用i—vector处理。但是这种聚类方法只适用于离线处理，对于低延时的处理要求还是无法满足。  

为了解决这个问题，用神经网络训练得出的嵌入物被用来当做一种i-vector的补充，异或是替代品，研究表明用神经网络得出的结果，在MFCC上的BIC指标表现会更好，尤其是短时延场景。这里的神经网络一般都通过Siamese或者triplet loss来处理双输入的对比性loss，同时一般使用LSTM来处理不同长度的输入。此外，为了生成嵌入物，神经网络还已经应用到了端到端的SCD系统中，daily paper1就是一个典型的应用，在这种系统中，预测结果直接通过神经网络的输出得出，而不需要使用距离阈值来进行判断。  

这篇paper的创新点在于，将speaker embeddings的学习和SCD的端到端方法结合到了一起（……），将两个片段（改变前后）的Siamese嵌入物feed到SCD系统的FC层分类器里，将embedding的学习过程本身作为Siamese层的预处理。这里他们用了三个预处理机制：性别分类，对比损失和triplet loss，之后同时尝试了单独训练分类器和同时训练分类器和预处理层。之后作者将这个网络应用到了低延时的系统中，将最大片段时长限制在了2s，最后得到在ASR决策边界下性能得到了大幅提升。此外，他们还对比了不匹配的测试片段时长下i-vector和神经网络embeddings的表现差异，最后评价了他们所做的低延时的SCD系统在ASR片段边界下的预测性能。  

## System  

其实主要的东西在这篇paper的Introduction里面已经说的非常清楚了，下面的内容就再说一下实现的细节。简而言之，他们的网络就是使用了Siamese网络来用Bi-LSTM同时处理两个片段的输入，然后产生两个embedding，将其导入神经网络分类器中得出最后的结论，该系统最终可以判断对话中改变的次数和具体时刻。  

Siamese网络的细节如下：三个Bi-LSTM层后接两个FC层，BLSTM和FC的衔接是通过计算最后一个BLSTM层在该时刻的前向和后向的平均激活函数值，将结果导入FC层实现的，同时根据前面所提到的，用三种损失函数进行预训练，具体如下：  

#### Gender Classification  

首先是使用二分交叉熵损失来训练一个性别分类的网络，这其实就是一种多类别语音分类的二元简化版本，给出的公式也就是最简单的二元交叉熵函数，没什么好说的。  

#### Contrastive Loss  

Siamese的典型损失函数就是LeCun的对比损失，使用对比损失的公式就好了，也没什么好说的。  

#### Triplet Loss  

Triplet loss是在FaceNet里面提出的，CS231n中貌似也有提到过，主要是通过一个anchor和两个相反的样本positive和negative组成，这里就不讲具体细节了，这篇paper作者大讲特讲triplet的基础概念，也没加个引用，同样的放上了triplet loss的公式，也没什么好说的……  我觉得作者列出这三个小标题知识为了凑字数和页面到4页整……这一段实在是太水了，三个损失函数讲了半张纸……  

## Experiments  

实验采用的数据集是BN-144，有144小时的音频。


---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
