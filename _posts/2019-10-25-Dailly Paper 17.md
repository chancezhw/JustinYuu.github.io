---
layout: post
title: "Daily Paper 17"
description: "Notes"
categories: [CV-classic]
tags: [Paper]
redirect_from:
  - /2019/10/25/
---

# Daily Paper 17 - OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks  

## Introduction  

今天的paper是CV经典论文列表里的最后一篇，内容是非常有名的OverFeat。作者使用卷积神经网络创建了一个集成的框架，来同时进行物体的分类、定位和检测。作者同时展示了如何将滑动窗口和多尺寸训练应用到卷积神经网络中，并提出了一种通过预测边框来进行定位的新深度学习方法，当进行目标检测时，边界框进行累积，而不是像其他方法那样进行非最大值抑制。作者发现不同的任务可以通过一个共同的网络来同时学习，这种集成的网络在ILSVRC13定位中获得了第一名，并在检测和分类中表现的也不错，比赛之后，作者又对检测任务的模型进行了调整，最终构成了最终的模型OverFeat。  

虽然ImageNet的数据包含一个大致充满图像的中心目标，但是目标在图像中的大小和位置有着显著差异，作者想解决这个问题，所以提出了三个想法：1.使用多个固定大小的滑动窗口移动，对每个扫过的窗口图像做CNN预测。该方法的缺点在于窗口没有包含整个目标，甚至中心也没有，只是包含了一部分（比如狗狗的头），虽然适合做分类，但是定位和检测效果很差。2.训练一个卷积网络，不仅产生分类的分布，还产生预测框（预测目标的大小和位置）。3.累积每个位置和尺寸对应类别的置信度。  

作者在Related Work中提到了AlexNet，其展示了CNN可在图像分类和定位任务上取得了优秀的表现，但是并没有公开描述他们的定位方法。这篇论文是第一次清晰地解释CNN如何用于定位和检测。  

作者认为三大任务按照难度的从易到难应该是分类、定位、检测，并且前边的任务是后面任务的一个子任务，虽然作者将其整合到了一个网络中，但是作者还是分别进行阐述。对于分类，使用top-5错误率作为评判标准；对于定位，除了top-5错误率之外还需要IOU大于0.5；检测问题最为复杂，不但要找到多个目标并进行分类，还要找出目标的位置，使用mAP作为评价指标。定位和分类任务使用相同的数据集，而检测使用另外的数据集，里面的物体尺寸会略小一些。  

## Classification  

分类的网络架构类似AlexNet，不过在网络设计和测试阶段两方面做了一部分改进。作者做了两个版本的网络，一个精确版一个快速版，网络的前5层和AlexNet相同，但是有几个不同点，一个是没有使用对比均一化，另一个是没有使用重复池化，最后就是stride用2代替4，导致第一层和第二层的特征图会略大，大的stride会提高速度但是降低精度。  

该网络和AlexNet最大的不同之处在于测试阶段使用了不同的方法来预测。AlexNet在测试阶段对256\*256的图像做裁剪（四个角落和中间）和水平翻转，得到5\*2也就是10张227\*227的图像，然后送进网络里面得到10个结果求平均来进行预测。这样的做法有两个问题，裁剪时可能忽略了图像的一些区域，以及10张图像有很多重叠部分导致了冗余计算。而该网络的测试阶段使用了两个重要的方法：多尺度测量和滑动窗口，下面具体介绍。  

### Multi-Scale Classification  

多尺度分类现在看来并不是新颖的方法了，但是这一方法最先在这篇paper中提出，多尺度分类可以在保持效率的前提下提升鲁棒性。不过由于下采样率是36，所以每隔36个像素才可以生成一个分类向量，这种输出的稀疏分布导致了表现的下降，这是由于图像中的物体并不是严格对齐的，换言之网络的表现很大程度上取决于图像中的物体是否对齐的好，所以作者使用offset池化来规避这一问题,offset可以将下采样率的36改为12。  

接下来详细的讲一下分辨率是如何增加的，作者用第五层的暂未池化的特征图为例子，由于多尺度测量中作者使用了6个scale，这里选的是scale2的20×23这一尺寸中的第一维度20作为示例。传统的做法就是以3为stride进行池化，得到长度为6的池化后序列，而作者采用offset的方法，移动一定位置之后再进行池化，这里移动的位置为1和2，再加上初始的池化，一共得到3个长度为6的序列。这只是一维的结果，二维就是3×3=9个结果，再将这9个结果进行集成预测，具体来讲就是把这6×6的序列分别导入到卷积核中，得到2×2的特征图，由于有3种offset方式，所以交错排列得到了最后的6×6的特征图，规模和不加offset的还是相同的。由于有6个scale，并且会进行水平的翻转，所以会重复12次，在12次里面的每一次都取位置信息的最大值，从而得到12个长度为类别数量C的向量，再将这12个向量取平均，得到最终的C维向量，求top-1和top-5误差率。最终的结果显示多尺度测量的误差率明显小于单尺度，不过offset池化的提升并不是很大，但是还是有一点作用的。  

### ConvNets and Sliding Window Efficiency  

另一个重点就是滑动窗口，与其他滑动窗口不同的是，这里的滑动窗口共享公共区域的计算，这样就避免了大量的重复性计算。在测试的时候，作者将一个更大的整张图片放在卷积层里，与训练的不同在于训练的时候输出的是一个1×1的输出值，而测试的时候输出的是一个小尺寸的图，然后对齐进行平均或者最大池化方式也可以得到最终的输出值。不过这种方式的好处在于，在测试的时候可以使用更大的图像，产生更多的输出，得到更好的预测结果，此外相对于传统的滑动窗口来说，这里只需要执行一次，保证了原有的效率的同时可以适应不同尺寸的图像，也不再局限于固定的AlexNet式的裁剪方式，提高了网络的鲁棒性。  

其实这种将最后的FC层取消改成1×1卷积的方式就是后来很火的FCN，全卷积网络。FCN和这里的优势是一样的，即可以接受任意大小的输入，避免了重复存储和计算，更加高效，不过这里仅仅将FCN应用在了测试中。  

## Localization  

接下来是定位。作者将分类网络中的分类层替换为一个回归网络，用于预测边界框的位置和大小。回归网络有两个FC层，分别由4096和1024个channel，根据预测的边框和实际的边框之间的l2距离作为损失函数，对于回归网络得到的一系列bounding box，该论文不是通过传统的非极大值抑制，而是使用了累积预测的方法。首先对于每个scale计算出前k个类别，对每个类别计算出所有的bouding box，然后合并所有scale的bounding box得到集合B，重复以下步骤：  

(b<sub>1</sub><sup>\*</sup>,b<sub>2</sub><sup>*</sup>) = argmin<sub>b1≠b2∈B</sub>match_score(b1,b2)  
if match_score(b<sub>1</sub><sup>\*</sup>,b<sub>2</sub><sup>*</sup>)>t, 停止  
否则set B←B\{b<sub>1</sub><sup>\*</sup>,b<sub>2</sub><sup>*</sup>}∪box_merge(b<sub>1</sub><sup>\*</sup>,b<sub>2</sub><sup>*</sup>)  

其中match_score(b1,b2)计算的是两个box中点的距离和交集区域的面积之和，当它大于某个阈值时算法停止box_merge(b<sub>1</sub><sup>\*</sup>,b<sub>2</sub><sup>*</sup>)计算的是两个box坐标的平均值,通过合并具有高置信度的box来得到最终预测，这种方法可以淘汰那些低置信度以及低连续（多个box相差很远）的类别，会更加鲁棒。  

作者采用的实验是直接送到ILSVRC13定位大赛中，结果夺冠了，证明这个系统是最好的……在ILSCRC12验证集上进行实验，结果表明多尺度测量的尺度为4的时候top-5错误率最小，为30.0%。值得注意的是，作者为每一个不同的类训练了一个不同的分类器，最终的结果居然不如使用相同的分类器表现要好，作者分析这可能是因为样本过少导致训练不充分欠拟合所致。  

## Detection  

最后简单的说了一下检测。检测的训练和分类的训练差不多，只是分类最后输出的是1\*1的一个输出，而检测产生的是n\*n的spatial输出，一张图像的多个位置被同时训练，和定位任务相比，最主要的不同是需要预测一个背景类，即一个没有物体的图像，这需要进行额外的判断。不过独立的引导过程使训练变得复杂，并且在负样本的收集和训练次数之间可能存在不匹配的风险，此外bootstrapping passes的尺寸需要在小数据集上进行调整，不然会导致训练的过拟合。对此作者对负样本进行了负训练，虽然训练的代价很昂贵，不过使得整个过程给为简单，正确率更高。  

最后作者在ILSVRC14检测中得到了第三名，mAP为19.4%，后来的改进方案获得了24.3%的mAP。  

## Conclusion  


本文使用一个CNN来集成三个任务，分类，定位和检测，具体解释了CNN是如何被用于定位和检测的，并提出了一个多尺度的，滑动窗口的方法，在检测、定位和分类三个任务中都得到了很好的表现。以现在的视角来看，当时的准确率或者mAP可能非常低，但是在当时，这的确是一个值得称赞的重大突破。  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
