---
layout: post
title: "Convolutional Neural Networks Chapter 2"
description: "Notes"
categories: [Convolutional-Neural-Networks]
tags: [Python]
redirect_from:
  - /2019/06/29/
---

# Convolutional Neural Networks Chapter 2  

第一周硬是学了两个星期，剩下的这三周课程进度要加快了，争取一周内学完。  

## Case Study  

这周的课程主要是介绍CNN的应用，吴恩达认为通过研究实例可以使自己的神经网络变得更好更有效，也可以更为有效的学会神经网络的应用。 

首先介绍了一些应用比较广泛的网络，例如LeNet-5、AlexNet、VGG-16等经典的神经网络，其差异主要体现在步长、过滤器数量、池化方式、激活函数的不同上。  
以上介绍的都是比较古老的网络，接下来介绍了一个比较新的神经网络——残差网络(ResNets)，它建立了一个'short cut'，也叫做'skip connection',使得激活函数计算后的结果al通过快捷路径而不是原始路径插入到很靠后的ReLU之间。而插入的部分称为残差块，多个残差块便构成了残差网络，其在深层网络中的表现比普通网络更好。  

接下来的问题在于，残差网络成功的原理是什么。吴恩达认为，对于这些额外的层来说，学习恒等函数非常容易，因此可以保证不会影响性能。很多时候，你可能会很幸运的提高网络的性能，或者至少有个不损害性能的底线，然后运用梯度下降来逐步提高其性能。我感觉吴恩达讲的不是太详细，因此找了一篇博客学习一下：[残差网络](https://www.cnblogs.com/wuliytTaotao/p/9560205.html)。  残差网络的原文链接在这里：[Deep Residual Learning for Image Recognition](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)  

接下来吴恩达介绍了1×1卷积的作用。显然1×1卷积并不能起到卷积的效果，它只是将所有的输入数据放大或者缩小了同倍数，但是它还是有别的作用，首先比较好理解的作用便是升维/降维，通过设置不同的过滤器数量，从而将数据的维度变成过滤器数量的大小，也就是缩小了数据的通道数。至此，缩小长宽可以使用池化层，缩小通道数可以使用1×1卷积，数据中所有的部分都可以被缩小/增加了。此外，它还可以利用后接的非线性激活函数来增加非线性，具体来讲，可以使用通道规模相同的1×1过滤器，使得完成一次卷积+非线性整流后可以达到规模不变的效果，那么在这一次操作中，由于平白无故的多进行了一次非线性操作，因此所训练的网络可以学习到更为复杂的函数形式，从而使神经网络更为强大。  

本节的最后介绍的是inception网络，具体来讲，Inception v1的网络，将1x1，3x3，5x5的conv和3x3的pooling，堆叠在一起，一方面增加了网络的width，另一方面增加了网络对尺度的适应性。可是这样仍然会有比较大的计算量，因此在3×3,5×5conv的后面和3×3pooling的前面各添加一个1×1卷积层，从而达到降维的目的。这便是GoogLeNet的inception v1。inception其实很难翻译，搜索inception会搜索出一个电影《盗梦空间》，事实上inception network的名字正是出自这一电影，由于电影中有过一句台词：we need to go deeper，这与这一网络的目的不谋而合，因此便用这个名字命名该神经网络。除了这一版本的inception，也就是inception v1，还有v2,v3,v4等多个版本，有空再去看看具体的改进。  

## Practical advices for using ConvNets  

这一部分是对于应用卷积网络的一些建议。首先是善于运用网上的开源项目，吴恩达教授演示了实现残差网络的实例。用网上的开源项目的好处是你可以运用网上已经训练好的项目来进行迁移学习，这可以大大减轻自己的工作量，节省大量的时间。因此接下来就用了一个视频来介绍迁移学习,通过具体的实例来介绍如何应用他人训练的权重来初始化应用到自己的神经网络中。  

f此外，更多的数据几乎对所有类型的计算机视觉工作都是有益的，因此数据增强（data augmentation）便起到了很好的作用。在第二门课程中就介绍过了数据增强和迁移学习，这里相当于再次复习一遍。对于同一张图片，可以通过镜像、翻转、裁剪、旋转、扭曲、变形等一系列操作使其变成自己需要的形状。此外，还可以通过色彩转变来对图片进行干扰，采取不同的红绿蓝数值来改变RGB通道的数值。其中一种色彩增强的方式称之为PCA，也叫做主成分分析，这在吴恩达教授之前的《机器学习》这门课程中有过记录。数据增强这一部分可以通过多线程处理和深度学习的训练线程同步进行，从而提高训练效率。  

这一节的最后一个视频，吴恩达教授用来介绍目前计算机视觉领域的发展以及他的感想。在比赛和基准数据测试中，有一些小tips可以提高表现，首先是集成，想好了要的神经网络之后，可以独立训练几个神经网络，并平均它们的输出。比如说随机初始化三个、五个或者七个神经网络，然后训练所有这些网络，对输出y进行平均计算，而不要平均权重，可能会在基准上提高1%，2%或者更好。但因为集成意味着要对每张图片进行测试，可能需要在从3到15个不同的网络中运行一个图像，会让运行时间变慢。其次是Multi-crop，Multi-crop是一种将数据扩充应用到测试图像中的一种形式，在测试图片的多种版本上运行分类器，输出平均结果。如把猫的图片复制四遍，包括两个镜像版本。如取中心的crop，然后取四个角落的crop，通过分类器来运行它。集成的一个大问题是需要保持所有这些不同的神经网络，占用了更多的计算机内存。multi-crop，只保留一个网络，不会占用太多的内存，但仍然会让运行时间变慢。  

## Programming assignments  

本次编程作业介绍了keras框架的用法，并用keras完成残杀网络的实例。这是这一系列课程中除了TensorFlow以外介绍的第二个框架，因此编程作业分为两部分，学习keras和应用keras。[源码链接](https://github.com/JustinYuu/Deeplearning-study/tree/master/Convolution%20Nerual%20Network)  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
