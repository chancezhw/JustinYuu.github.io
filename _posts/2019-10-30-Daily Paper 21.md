---
layout: post
title: "Daily Paper 21"
description: "Notes"
categories: [MMML-Self Supervised]
tags: [Paper]
redirect_from:
  - /2019/10/29/
---

# Daily Paper 20 - Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization  

## Introduction  

这周小组内下了新的任务，看一些自监督的多模态机器学习方向的paper，所以暂时把VLN领域的paper放一放，先把任务完成。  

今天是第一篇，也是比较有代表性的一篇，是FAIR和达特茅斯大学共同发表在nips2018上的，其实FAIR的那位也是达特茅斯的毕业phd，所以几乎相当于是达特茅斯的paper。paper主要讲的是自监督同步的音视频模型协同学习，由于在视频中，图像和音频存在着自然的关联，作者在这篇paper中利用此关联来学习自监督的音视频时序同步的通用而有效的模型。作者表明一个校准的课程学习方案、一个对于负样本的仔细选择和对比度损失的使用是从优化的模型中获得强大的多感官表示，以实现音频-视频时序同步的重要因素。在没有调优的情况下，最终的audio features能够在已有的音频分类benchmark上得到优于或等同于现有模型表现的结果。与此同时，作者的视频子网络提供了一种非常有效的初始化方式，可以有效的提高基于视频的动作识别模块的准确率，具体来讲，与从头开始训练相比，作者的自监督预训练模型获得了UCF101上19.9%的动作识别率提升和HMDB51上的17.7%的动作识别率提升。  








---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
