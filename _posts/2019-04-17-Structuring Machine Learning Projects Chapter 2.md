---
layout: post
title: "Structuring Machine Learning Projects Chapter 2"
description: "Notes"
categories: [Structuring Machine Learning Projects]
tags: [Python]
redirect_from:
  - /2019/04/17/
---

# Structuring Machine Learning Projects Chapter 2    

这门简短的课程只有2章，这是第二章，也就是最后一章。虽然内容比较少，但是每一章内的内容饱和度还是有的。  

## Error Analysis  
本章的第一节学习的是误差分析。误差分析是项目过程中很重要的一步，那么显然第一步是找出误差存在的原因。这里Andrew给的建议是通过列表将错误的数据分类，然后得到每个错误类型在所有的错误例子中所占有的比例，进而进行校正误差。  
发现误差之后要进行校正，值得注意的是，深度学习对于随机误差来说是robust的，但是对系统误差不是。因此我们主要的目的就是尽可能降低系统误差。这个时候要进行一个二次分类，将误差中的由于数据标签标注错误而导致的误差挑选出来。这一部分是系统误差中很重要的一种，因此我们要花时间通过重新分组标注来解决掉这部分误差。  

## Mismatched training and dev/test set  
很多时候，开发者们为了提高训练集的规模，会将一些与测试集和开发集数据分布并不相同的数据放到测试集中去训练，这就造成了开发/测试集与训练集的规模不匹配的问题。吴恩达举了一个例子，是关于图片识别的来源问题。如果目的是为了更好的识别移动应用图片的分布，那么就不要将大量的网页图片放到开发集和测试集中。而问题是大部分的图片都是来自网页图片，如果全部不用又太浪费，而且就没有大量的数据做训练了。因此吴恩达建议将所有的网页图片放到训练集中，再将一小部分移动应用图片放到训练集中。而在开发集和测试集中，大比例放入移动应用图片，小比例掺杂来自网页的图片。这样虽然训练效果可能会比较差，但是至少目标是对的。  
接下来介绍了一种称为dev-training set的数据集，这是从训练集中分出来的一种新的数据集，其分布方式和训练集一样，但并不是为了训练使用。通过人类水平、训练集误差、训练-开发集误差、开发集误差之间的比较，可以分析出不匹配现象出现的原因是因为高偏差还是高方差。具体的讲，训练集误差和人工误差之间的差别就是上文所讲的可避免误差，而训练-开发集误差与训练集误差之间由方差决定。而训练-开发集与开发集之间的误差不相同则是由于数据不匹配所致，可以考虑统一化数据的分布情况。最后，测试集和开发集之间的误差不匹配主要是因为过拟合程度不同，可能调的太偏向于开发集了，这时候推荐找一个更大的开发集。  
本节的最后Andrew强调了数据不匹配的重要性。事实上数据不匹配经常会在不经意间出现，他举了游戏赛车和语音识别的两个例子，我不展开放在这里，但是总而言之数据的不匹配经常会由于训练集数据来源的单一或者不全面所导致，这会导致训练结果的过拟合。因此对于训练模型，误差分析是非常重要的，误差分析的具体方式在第一节中有所阐述。此外人工合成数据是一种很方便而又有效的方法，例如在语音识别中作用很大，但是有可能人工合成数据只是模拟了所有可能样本子集中的数据，这样结果就会向训练集样本方向过拟合。因此在人工合成数据的时候要注意这一点。  

## Learning from multiple tasks  
这一节介绍了一个相当给力的学习方式：迁移学习。简单来讲，就是从某一个神经网络上学到的东西，应用到其他神经网络上。比如在CV方面，识别不同的物体就可以通过迁移学习进行转换。在迁移学习中，要是你对神经网络的所有参数进行重新训练，那么这样训练的初始化阶段，有时候被我们叫做预训练（pre-training）。原因是我们在是使用迁移前的数据来预初始化（pre-initialize）或者说预训练神经网络的权重。然后如果你在之后对所有的权重进行更新，那么在迁移后的数据上的训练有时候被我们叫做微调。  
显然迁移学习有其适用范围，这里有三条:1.A任务和B任务有相同的输入（类型）。2.A任务的数据必须比B任务多，这是因为B任务中的数据比A任务中的数据更有价值，那么质不够量来凑，A任务的数据就要多点。3.A任务的低层次特征会帮助任务B达成目标。完成这三条条件的同时，还要有一个明确的目的，就是将B任务做的更好，那么这个时候就可以采取迁移学习的方式。  
迁移学习是有前后顺序的，在多任务学习中，可以让多个任务同时开始，让一个神经网络同时做几件事，让任务互相帮助、协同工作。这里Andrew举了一个自动驾驶汽车的例子。通过一个神经网络，可以同时检测人行道、汽车、停止标志和信号灯。实现方式是将y向量化，向量里数据的数量就是想要检测的目标数，这样就可以使一个数据具有多个标签。由于在一个神经网络中，特征值可以共享，这样相比于四个神经网络而言损失函数更小。事实上，多任务学习的效果比迁移学习要好，但是由于其应用的复杂性和对数据集规模的要求较高，其应用面比迁移学习要小的多。对于一个比较小的数据集，迁移学习能够得到更好的应用。  

## End-to-end deep learning  
本章的最后一节介绍了端到端学习。


---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
