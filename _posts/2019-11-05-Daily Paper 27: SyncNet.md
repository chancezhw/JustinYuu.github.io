---
layout: post
title: "Daily Paper 27: SyncNet"
description: "Notes"
categories: [MMML-Self_Supervised]
tags: [Paper]
redirect_from:
  - /2019/11/05/
---

# Daily Paper 27 - Out of time: automated lip sync in the wild  

## Introduction  

这篇是VGG组在ACCV2016 Workshop上的一篇paper，这是比较早的一篇，主要研究的是视听时序对齐任务，提出了一个比较经典的双流卷积网络框架，主要应用在唇语识别和活跃说话人检测这两个下游任务上，并均取得了当今的最好表现。  

作者解决视听时序对齐任务的初衷是由于在电视节目的传输中和电影的配音中，经常会出现大规模的延迟，常规方法是使用timecodes等标注来解决，但是使用视频中的图像内容来对齐是不常见的。作者在这篇paper中就提出了一个语言独立和说话人独立的嘴唇对齐的解决方法，只使用电视观众能看到的视频和音频流就可以解决该问题。整个模型最重要的部分在于卷积网络架构和对声音和视频中的嘴型联合embedding的pipeline，整个网络是自监督的，这个模型是第一个解决视频音频时序对齐问题的系统。  

该模型不仅仅能够解决时序对齐任务，还可以有效的解决很多其他下游任务，这里作者主要介绍了三种可以有效解决的下游任务：1.判定视频中是否存在嘴唇不对应的情况；2.在多个人脸中检测说话者；3.唇语识别。在唇语识别和说话人检测这两个下游任务上取得了当今的最好表现。  

## System  

该网络称作SyncNet，该网络最大的特色是应用了Two-stream双流网络的形式。对于音频流，输入的音频数据是MFCC值，被编码成为一个表示每一个时间步和频带的MFCC热度图，热度图的横轴是时序，纵轴是13个MFCC特征，热度图的前三和后三行用于降低边界影响。整个网络的架构基于VGG-M进行，输入的就是之前产生的热度图，热度图的尺寸为13×20个像素，这是由于热度图中有20个时间步和13个MFCC特征决定的。  

对于视频流，输入的形式是一系列嘴部的灰度图像，输入的维度是111×111×5的5帧组合图像，这在25Hz的帧率下大概等于0.2秒的视频。网络使用视频语音识别任务的网络架构，整个网络架构基于早期融合模型，使得整个网络更为紧凑，训练更加快速。网络的损失函数使用了对比损失函数，两个stream的训练参数不共享，使用动量优化的随机梯度下降来更新优化权重。  

此外作者还进行了data augmentation，这里对声音大小随机调整了10%，对于负样本进行随机的裁剪，对于视频采用了标准增强方法（随机裁剪、旋转、色彩偏移等），dataset使用2013到2016的BBC新闻节目，分为训练集、测试集和交叉验证集。  

## Experiments  

接下来看该系统的实验结果，作者使用肉眼评估，结果单个样本(0.2s)的准确率是1%，在clip上的整体准确率大于99%，此外作者还发现该模型对于外语视频的处理定量分析的结果也相当好，网络在中等配置电脑上的运行速度也相当快，基本上等于×0.3实时。  

接下来看在实时说话人检测应用上的表现，作者定义一个时间偏移内的置信度分数为欧氏距离的中位数和最小值的差，正常来讲在一个多人脸视频中，说话人对应的分数应该是最高的，而不说话的人脸对应的分数应该接近或等同于0。和单模态模型不同的是，该模型也可以处理说话者不在图像里的情况。作者使用Chakravarty的数据集和评估方法，在10帧和100帧的窗口内进行测试，结果显示100帧黄口的表现几乎是完美的，不过帧数过大会导致模型无法检测短时长发言者，不过在此实验中并无这种情况出现。  

第二个下游任务是唇语识别，作者使用OuluVS2作为数据集，使用一个单向LSTM作为分类器，有250个隐藏单元。LSTM运行在一个5帧的滑动窗口下，每个时间步为1帧，在序列结尾返回分类结果，最后的测试集显示SyneNet的表现显著优于其他模型。  

## Conclusion  

总结一下，作者主要设计了一个双流卷积网络，用来处理视听时序对齐任务，具体来说是检测嘴部的嘴唇与其说话的声音是否对齐。结果显示该系统能够在本地机器上实时检测并取得了很高的准确率。此外，该模型还可以应用于唇语识别和实时说话人检测等下游任务中，应用前景非常广阔。  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
