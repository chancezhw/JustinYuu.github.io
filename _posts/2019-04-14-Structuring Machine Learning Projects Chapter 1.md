---
layout: post
title: "Structuring Machine Learning Projects Chapter 1"
description: "Notes"
categories: [Structuring-Machine-Learning-Projects]
tags: [Python]
redirect_from:
  - /2019/04/14/
---

# Structuring Machine Learning Projects Chapter 1    
第三门课程的名字叫做Structuring Machine Learning Projects，这门课的目的是为了给深度学习的学习者做自己的项目时可能会遇到的问题提供一些解决方法，以及整体的一些策略。整门课程的内容并不多，我个人感觉学习之后可以开展自己简单的深度学习项目了。  
第一周并没有编程练习，因此将会学的快一点，争取一天搞定。  

## Introduction to ML Strategy  
第一章是导论，主要介绍这门课的意义和内容。正如吴恩达所说，正确的机器学习策略可以使工作事倍功半，而错误的机器学习策略只会使工作变得漫长而又复杂，效果还不好。正交化指的是调整合适的参数从而使效果更为合理的方法。那么正交化，也就是调参的目标就是在测试集->开发集（交叉验证集）->测试集->实际应用中都有很好的表现，那么正如箭头的顺序所致，目标的难度和重要性都是依次增加的。  

## Setting up your goal  
这一节首先介绍了一些量化的方式，正如之前讲过的一样，用查准率、召回率和F1指数来评判性能的好坏。此外，也可以用准确率和响应时间等参数来衡量性能，比如说语音应答功能。因此，不同的功能会有不同的评价方式，这里应该是列举了几种以供自己量化项目性能的时候参考。  
开发集，也叫做交叉验证集是很重要的一部分测试数据，我们在训练集中可以训练各种不同的训练模型，然后进去开发集中用之前所学习的量化评估方式来评估其不同的性能，挑选出最适合、表现最好的一种或者几种模型，然后在测试集中进行测试。但是值得注意的是，交叉集的测试数据必须足够广，至少要和所应用的方向、测试集相一致，这样才不会出现方向错误的问题。  
至于数据在训练集、开发集、测试集的分布问题，前面的课程已经讲过了，所以这里就不重复记录了。  

## Comparing to human-level performance  
一个很显然的理论是：如果你的机器学习算法表现并未超过人类级别的表现，那么你始终有很大的进步空间，或者说至少是一个进步的方向，那么你可以根据这个目标来进行一些调整，事实证明这一环节一般是很快的。但是如果你的算法表现已经超越了人类，那么进步的速度将会明显变慢，这也可以理解，因为用作比较的标杆已经被超越了，那么改善空间也并没有那么大了。总的来说，将自己的机器学习算法表现与人类级别的表现作对比，可以使自己的算法以比较快的速度得到迅速提升。  
此外，由于偏差的存在，在训练集中表现很差的算法很有可能是大偏差的，那么通过与人类的表现作对比，可以比较明显的判断自己的算法是否存在大偏差。贝叶斯误差即为能达到的最小误差的极值，也就是说不存在低于贝叶斯误差的误差值。那么显然我们的目标就是尽量把误差值向贝叶斯误差靠拢。那么人类表现的作用就是能够估计出贝叶斯误差的值。具体的估计方法我的理解就是看看最顶尖的水平是多少，那么就把贝叶斯误差的极限定在那个水平上的误差，如果不断的发现有更高水平的情况存在，那么就不断的修正贝叶斯误差。  
也就是说，虽然贝叶斯误差本身是一个极限误差，但是我们并不能够直观的推算出具体的值，只能通过人类的极值来推断。那么显然人类的极值并不是贝叶斯误差，但是为了设定一个小目标，就只能这么等效代替了。那么这就是通过人类表现来定义贝叶斯误差的方法。那通过这种方法，可以评判自己的模型表现，以及是否存在偏差和方差的问题。  
之前讨论的情况都是在超越人类性能之前，那么现在就要考虑一下超越人类的性能之后可能会出现的情况了。在一些非自然感知领域，比如推荐、预测等领域，机器学习算法做的已经比人类好多了，但是在一些自然感知领域，比如nlp，cv等领域，机器学习超越人类还是比较困难。但是在很高的数据规模下，机器学习算法的表现超越人类也是可能的。  
最后总结一下，得出一套合理的解决问题的模板。首先通过人类表现和训练集结果作对比，从而避免高偏差。一系列可行的操作包括训练更大的模型、使用更长的/更好的优化算法、用一些更高级的神经网络架构（比如CNN、RNN等）或者改变一些超参数。然后就可以对比训练集的结果和开发集的结果，从而避免高方差。那么就和之前所讲的解决方式一样，通过采用正则化、扩充数据集、改变超参数和神经网络架构来完成。  

## Flight Simulator  
Flight Simulator这个标题实在是迷惑了我，我以为这个课程把飞行模拟这个大作业给漏了，去论坛看了看才明白，“飞行模拟”本身就是一个比喻。飞行员的许多训练并不是在真正的飞机上完成的，而是在飞行模拟器中完成的。那么我们作为深度学习的初学者，用数周乃至数月来做一个大项目显然是不太现实的，那么就可以通过模拟这种形式来练习。本门课程的两个quiz就是“深度学习模拟”，通过完成一系列问题来熟悉整个项目开发的流程，以及解决项目开发过程中出现问题的方法。  
具体的内容我就不放在这里了，我感觉这种优秀的练习题，应该每个人亲自去完成才可以达到效果。  

## Heroes of Deep Learning  
又到了喜闻乐见的采访环节，本期嘉宾是Andrej Karpathy，我很好奇LeCun为什么到现在还是没被采访，可能在后面学习CNN的时候采访更合适吧。  
本期采访的大牛也是鼎鼎有名的，Karpathy是李飞飞教授的弟子。按照惯例，先将他的个人经历，这位大佬初入DL是因为Hinton的一门课，第一门课就是这位大佬，我好羡慕啊0_0。然后他在上的另外一门机器学习课程中，他并不满意大家所用的算法，所以就想研究一些新的有趣的算法，于是他开始研究神经网络，之后一直做到现在。这位大佬是ImageNet的人工分类基准，用比喻的手法的话他就是世界杯决赛的裁判，或者类似高考的参考答案，也就是说他代表了人类在图像分类的最高水平。他的训练手法是用一到两周来分类大量的重复性图片，例如确定狗的品种，通过这种训练他得到了人类分类的成功率，也就是这周所学的人类表现。显然如果训练类似模型，可以用这个结果作为假设贝叶斯误差。最后他也惊奇的发现他的神经网络已经超过了人类表现，这的确是很了不起的成功率。  
我最敬佩的是他用了一些时间，放下了手中的研究，在课堂上或者网络上免费分享他的方法。他在采访中讲到这个领域最大的特点，也是最吸引人的一点就是它的日新月异，可能课堂上讲的论文就是一周前甚至昨天发表的，那么每个人都有走在时代前沿的感觉。我个人也喜欢这种感觉，在原来本科所在的材料领域，我最喜欢的事情就是阅读最新的研究成果，但是由于发表限制，最新的成果也是几个月之前的，并没有DL领域中的这么新，不过感觉还是不错的，有一种站在时代浪潮上的刺激感和成就感- -。  
接下来他讲了一些无监督分类的前景。现在有良好表现的大多是监督分类，但是无监督分类的前景和应用以及原理尚未明朗。据Andrej所说，他认为无监督学习最终会分为两条路，第一条就是类似监督学习的应用方向，用来提高目前模型的性能。而第二条建立的是一种称为人工通用智能的模型，与现有的监督学习不同，第二种道路建立的人工通用智能并不是将功能分开实现最后组装的，而是一种完全动态的神经网络，整个程序就想人类一样是一个完全整体的、动态的。两种道路最后实现的人工智能表现比较相似，但是道路完全不同，第一种是类似分治法的方式，而第二种却用了完全不同的整体化的，或者递进式的方式。  
最后是对初学者的建议部分。他拿了CS231n举例，认为不要一开始就用tf、torch这些框架，而是从底层的细节开始学起。也就是说不是直接学习用轮子，而是先学懂这些轮子是怎么写的。我也觉得很幸运，在我入门ML和DL的时候接触了这么多优秀的学习课程，可以从最底层的原理开始学起，而不是成为一个只会调参和掉包的five。  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
