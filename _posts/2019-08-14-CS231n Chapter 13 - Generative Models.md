---
layout: post
title: "CS231n Chapter 13 - Generative Models"
description: "Notes"
categories: [CS231n]
tags: [Python]
redirect_from:
  - /2019/08/14/
---

# CS231n Chapter 13 - Generative Models  

## Introduction  

这一周主要进行生成模型的学习，但是在这之前要先讲一下无监督学习。生成模型主要介绍三个，分别是PixelRNN和PixelCNN、Variational Autoencoders和Generative Adversarial Networks，最后一个也就是大名鼎鼎的生成对抗性网络GAN。  

## Unsupervised Learning  

无监督学习的概念在刚刚接触深度学习的时候就会被提到，无监督学习和监督学习不同，没有明确的目标label y，比如聚类、降维等。在之前吴恩达机器学习MOOC中学习过相关概念，这里是当时的笔记[链接](http://justin-yu.me/blog/2019/01/30/Machine-Learning-by-Andrew-Ng-Chapter-8/)，在这门课程中知识简要的提了一下，具体的内容还是要复习一下当时的笔记。  

## Generative Model  

生成模型的作用是给定一个训练的数据，能够生成同样分布的相似数据，这里为什么是一个非监督学习任务呢？答案在于我们需要用非监督学习来估计训练数据的潜在分布，这其实是非监督学习中的一个核心问题。  

生成模型可以分类成两个主要分支，Explicit dentisy和Implicit density，很多耳熟能详的模型都在里面。在explicit density分支下，又可以分为tractable density和approximate density，前者的模型是完全可见的信息网，比如NADE、MADE和PixelRNN/CNN，后者又可以分为Variational（变分自动编码机）和马尔科夫链（玻尔兹曼机），而在implicit density分支下，可以分为马尔科夫链（GSN）和Direct（GAN）。  

## PixelRNN/CNN  

首先我们介绍显式密度类型中的tractable density，即完全可见信息网。他们明确的模拟了数据分布的密度，使用链式法则去分解可能性，将输入的图像x分解为1维空间的分布，接下来将训练数据的似然最大化。那么我们如何来表示数据在像素上的复杂性分布呢？我们可以考虑使用C深度神经网络来表达这种复杂性。PixelRNN从角落里的像素里生成图像像素，由于每一个像素都与之前的像素有关（分布是整体的），所以我们自然而然的想到可以使用LSTM来完成。但是这个网络的缺点是序列生成速度很慢，所以我们尝试用CNN来代替RNN，仍然是从角落开始扩展，取待生成的像素点周围的像素，将这些像素导入CNN中，用softmax来生成下一个像素，我们通过最大化训练图像的似然来训练模型。  

总结一下，PixelRNN和CNN可以显性的计算似然p(x),显性的似然可以带来好的明确的评价指标，此外这个网络还能产生很好的样品。但是它也有缺点，比如序列生成的速度比较慢。那么自该算法发明以来，就一直被改进，比如给卷积层增加一个门，采用short-cut connection等。  

## Variational Autoencoders（VAE）  

接下来介绍变分自动编码机，首先我们先学习一些背景知识：何为自动编码集？自动编码集并不用来生成新数据，但是是一种无监督学习的方法，用来学习未标注数据的低维特征表示。那么具体是怎么学习的呢？我们首先输入数据x和特征z，然后用一个编码器encoder进行x到z的映射，然后再将特征z通过解码器进行decode成重建的输入数据x，使用L2距离作为损失函数值，同时我们在decoder的时候一般进行降维，从而保留x的重要特征，将不重要的特征剔除。这里encoder和decoder一般是对称的，一开始使用linear+sigmoid，后来使用深度的FC程，最后使用ReLU CNN，当然解码器就是upconv。那么我们可以看到自动编码机能够重建数据并学习特征，因此我们可以用这个来初始化一个监督学习模型，那么我们会进一步想，这些学习的特征z有捕捉训练数据中包含的变化因素的能力，那么我们可以用自动编码机来生成新的数据吗？这就引入了我们要讨论的变分自动编码机。  

变分自动编码机的数据x是从某种不可观测的隐式表征z中生成的，那么具体的生成过程是先从z的先验分布中采样，对于每种属性，我们都假设一个分布，这里采取高斯分布作为假设，然后我们在给定z的条件下，对x的条件分布概率采样。采样z的时候比较简单，比如高斯分布，但是对x的条件概率采样比较困难，这里可以使用神经网络来完成。然后我们使用decoder，选取隐性的表征，将其解码为表示的图像，接下来训练模型，最大化训练数据x的似然函数来寻找模型的参数theta，我们使用积分的形式来积分所有可能的z，用p(z)乘以p(x\|z)，然后对dz积分得到数据x的似然函数。但是这个积分很难积，并且计算p(x\|z)也很困难，所以我们无法直接优化似然。这里的策略是使用解码器decoder来建模的同时，定义一个编码器encoder网络q(z\|x)，将输出x编码为z，从而得到似然p(z\|x)，我们用他来估计后验分布p(x\|z),从而得到了数据似然的下界，这个下界比较容易解出，也更容易优化。  

具体的公式也很好理解，主要是用了一个贝叶斯公式，我就不放图了，最后的结果分为三项，第一项是对所有采样的z取期望，期望的内容是p(x\|z)，让p(x\|z)变大。第二项是KL项，让其尽可能减小，从而使得我们的近似后验分布和先验分布变得相似，从而使得z的分布和我们期望的分布类似。最后一项也是KL项是q(z\|x)关于p(z\|x)的，但是由于之前提到过p(z\|x)是不可解的，所以我们无法计算这个KL项，但是我们知道KL的divergence总是大于等于0.但是前面的两项是可以微分和优化的，我们可以找到其下限，而我们的训练就是最大化这个下限。  

我们再走一遍整个流程，首先我们将输入的数据x通过encoder编码器网络得到q(z\|x)，然后通过q(z\|x)来计算KL项，再通过给定的x分布对z进行采样，获得隐式变量的样本，然后将z导入解码器网络，计算x在z的条件下的协方差和均值，从而最终得到z的条件下x的分布。而我们的训练时最大化下界，在给定的z条件下，对训练的像素值取对数得到loss值，最大化被重构的原始输入数据的似然。在每一个minibatch，我们都对输入数据进行一次前向传播，然后再back prop更新我们的权重，包括encoder和decoder网络的参数θ和Φ。  

这一部分牵扯到了大量的概率论方面的知识，以及相当多的公式推导，即使回顾了好几遍我还是晕头转向的，需要过几天再回来复习一遍。这里是我找的一篇比较详细的VAE的推导和代码实现，这里是[链接](https://blog.csdn.net/ppp8300885/article/details/80070723)。  

VAE相对于自动编码器，加入了一些随机的成分，采用了随机分布和采样的思想，从而生成新的数据，而之所以称为variable，就是因为用近似的思想来解决分布难解的问题，用可解的下界来逼近不可解的上界。VAE的优点是这是一种principle的方法，这种对另一个神经网络q(z\|x)引用的思想可以作为有效的特征表示手段被其他任务所利用，但是其缺点是最大化似然下界并没有PixelCNN/RNN准确，此外相较于GAN来说没那么精确。  





---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
