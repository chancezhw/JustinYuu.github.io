---
layout: post
title: "CS231n Chapter 13 - Generative Models"
description: "Notes"
categories: [CS231n]
tags: [Python]
redirect_from:
  - /2019/08/14/
---

# CS231n Chapter 13 - Generative Models  

## Introduction  

这一周主要进行生成模型的学习，但是在这之前要先讲一下无监督学习。生成模型主要介绍三个，分别是PixelRNN和PixelCNN、Variational Autoencoders和Generative Adversarial Networks，最后一个也就是大名鼎鼎的生成对抗性网络GAN。  

## Unsupervised Learning  

无监督学习的概念在刚刚接触深度学习的时候就会被提到，无监督学习和监督学习不同，没有明确的目标label y，比如聚类、降维等。在之前吴恩达机器学习MOOC中学习过相关概念，这里是当时的笔记[链接](http://justin-yu.me/blog/2019/01/30/Machine-Learning-by-Andrew-Ng-Chapter-8/)，在这门课程中知识简要的提了一下，具体的内容还是要复习一下当时的笔记。  

## Generative Model  

生成模型的作用是给定一个训练的数据，能够生成同样分布的相似数据，这里为什么是一个非监督学习任务呢？答案在于我们需要用非监督学习来估计训练数据的潜在分布，这其实是非监督学习中的一个核心问题。  

生成模型可以分类成两个主要分支，Explicit dentisy和Implicit density，很多耳熟能详的模型都在里面。在explicit density分支下，又可以分为tractable density和approximate density，前者的模型是完全可见的信息网，比如NADE、MADE和PixelRNN/CNN，后者又可以分为Variational（变分自动编码机）和马尔科夫链（玻尔兹曼机），而在implicit density分支下，可以分为马尔科夫链（GSN）和Direct（GAN）。  

## PixelRNN/CNN  

首先我们介绍显式密度类型中的tractable density，即完全可见信息网。他们明确的模拟了数据分布的密度，使用链式法则去分解可能性，将输入的图像x分解为1维空间的分布，接下来将训练数据的似然最大化。那么我们如何来表示数据在像素上的复杂性分布呢？我们可以考虑使用C深度神经网络来表达这种复杂性。PixelRNN从角落里的像素里生成图像像素，由于每一个像素都与之前的像素有关（分布是整体的），所以我们自然而然的想到可以使用LSTM来完成。但是这个网络的缺点是序列生成速度很慢，所以我们尝试用CNN来代替RNN，仍然是从角落开始扩展，取待生成的像素点周围的像素，将这些像素导入CNN中，用softmax来生成下一个像素，我们通过最大化训练图像的似然来训练模型。  

总结一下，PixelRNN和CNN可以显性的计算似然p(x),显性的似然可以带来好的明确的评价指标，此外这个网络还能产生很好的样品。但是它也有缺点，比如序列生成的速度比较慢。那么自该算法发明以来，就一直被改进，比如给卷积层增加一个门，采用short-cut connection等。  

## Variational Autoencoders（VAE）  

接下来介绍变分自动编码机，首先我们先学习一些背景知识：何为自动编码集？自动编码集并不用来生成新数据，但是是一种无监督学习的方法，用来学习未标注数据的低维特征表示。那么具体是怎么学习的呢？我们首先输入数据x和特征z，然后用一个编码器encoder进行x到z的映射，然后再将特征z通过解码器进行decode成重建的输入数据x，使用L2距离作为损失函数值，同时我们在decoder的时候一般进行降维，从而保留x的重要特征，将不重要的特征剔除。这里encoder和decoder一般是对称的，一开始使用linear+sigmoid，后来使用深度的FC程，最后使用ReLU CNN，当然解码器就是upconv。那么我们可以看到自动编码机能够重建数据并学习特征，因此我们可以用这个来初始化一个监督学习模型，那么我们会进一步想，这些学习的特征z有捕捉训练数据中包含的变化因素的能力，那么我们可以用自动编码机来生成新的数据吗？这就引入了我们要讨论的变分自动编码机。  

变分自动编码机的数据x是从某种不可观测的隐式表征z中生成的，那么具体的生成过程是先从z的先验分布中采样，对于每种属性，我们都假设一个分布，这里采取高斯分布作为假设，然后我们在给定z的条件下，对x的条件分布概率采样。采样z的时候比较简单，比如高斯分布，但是对x的条件概率采样比较困难，这里可以使用神经网络来完成。然后我们使用decoder，选取隐性的表征，将其解码为表示的图像，接下来训练模型，最大化训练数据x的似然函数来寻找模型的参数theta，我们使用积分的形式来积分所有可能的z，用p(z)乘以p(x\|z)，然后对dz积分得到数据x的似然函数。但是这个积分很难积，并且计算p(x\|z)也很困难，所以我们无法直接优化似然。这里的策略是使用解码器decoder来建模的同时，定义一个编码器encoder网络q(z\|x)，将输出x编码为z，从而得到似然p(z\|x)，我们用他来估计后验分布p(x\|z),从而得到了数据似然的下界，这个下界比较容易解出，也更容易优化。  

具体的公式也很好理解，主要是用了一个贝叶斯公式，我就不放图了，最后的结果分为三项，第一项是对所有采样的z取期望，期望的内容是p(x\|z)，让p(x\|z)变大。第二项是KL项，让其尽可能减小，从而使得我们的近似后验分布和先验分布变得相似，从而使得z的分布和我们期望的分布类似。最后一项也是KL项是q(z\|x)关于p(z\|x)的，但是由于之前提到过p(z\|x)是不可解的，所以我们无法计算这个KL项，但是我们知道KL的divergence总是大于等于0.但是前面的两项是可以微分和优化的，我们可以找到其下限，而我们的训练就是最大化这个下限。  

我们再走一遍整个流程，首先我们将输入的数据x通过encoder编码器网络得到q(z\|x)，然后通过q(z\|x)来计算KL项，再通过给定的x分布对z进行采样，获得隐式变量的样本，然后将z导入解码器网络，计算x在z的条件下的协方差和均值，从而最终得到z的条件下x的分布。而我们的训练时最大化下界，在给定的z条件下，对训练的像素值取对数得到loss值，最大化被重构的原始输入数据的似然。在每一个minibatch，我们都对输入数据进行一次前向传播，然后再back prop更新我们的权重，包括encoder和decoder网络的参数θ和Φ。  

这一部分牵扯到了大量的概率论方面的知识，以及相当多的公式推导，即使回顾了好几遍我还是晕头转向的，需要过几天再回来复习一遍。这里是我找的一篇比较详细的VAE的推导和代码实现，这里是[链接](https://blog.csdn.net/ppp8300885/article/details/80070723)。  

VAE相对于自动编码器，加入了一些随机的成分，采用了随机分布和采样的思想，从而生成新的数据，而之所以称为variable，就是因为用近似的思想来解决分布难解的问题，用可解的下界来逼近不可解的上界。VAE的优点是这是一种principle的方法，这种对另一个神经网络q(z\|x)引用的思想可以作为有效的特征表示手段被其他任务所利用，但是其缺点是最大化似然下界并没有PixelCNN/RNN准确，此外相较于GAN来说没那么精确。  

## Generative Adversarial Model  

在之前的PixelCNN/RNN和变分编码自动机中，我们所做的事情都是定义并尝试求出具体或近似的密度函数，而如果我们直接放弃显式的对密度函数建模，而是爱只是从这个分布中采样获得表现良好的样本呢？我们可以使用生成对抗性模型来从博弈论角度出发，用2玩家博弈来从训练分布中学习生成数据。  

这里的瓶颈时我们想从一个非常复杂高维度的训练分布中取样，而这是没有直接的方法的。而我们的解决方法是从一个简单的高斯分布中采样，然后使用神经网络来学习从简单采样到复杂采样的转变。那么整个训练过程就可以看做双玩家博弈的过程，我们共有两个网络，一个是生成器网络，另一个是判别器网络discriminator network，这两个网络很有意思，生成器网络的目标是生成非常逼真的图像从而试图欺骗判别器网络，而判别器网络则要想办法来区分正确和假图像，指出哪些图像是生成器网络生成的。那么在两个网络相互博弈的过程中，生成器网络就在不断的学习和更新自身，从而能够生成越来越逼真的网络，在这个过程中，判别器网络就像一个陪练，当判别器网络的判别准确率逐渐变低的时候，说明生成器网络成为了一个优秀的生成模型。  

接下来看实现的数学细节，我们用一个minimax博弈目标函数来联合训练两个网络，我们的目标是让目标函数值在生成器网络参数上取得最小值，而在判别器网络参数上取得最大值。  

GAN是一个无监督学习，我们并不需要对数据进行标注，但是生成器生成的图片会被判别器标记为真1和假0，我们没有外部标签，但是判别器会给生成器的生成图片进行内部标注。此外联合训练两个神经网络是一件比较困难的事情，同时训练会使训练过程变得不稳定，所以选择好的目标函数从而获得更好的损失函数空间可以使得训练变得更加的平稳。  

在训练过程中，每一个训练步我们都先训练判别器网络，再训练生成器网络。由于判别器网络的训练需要用到真实图片和虚假图片，所以我们需要先用生成器网络生成小批量的虚假图片（从先验分布z中采样生成），再选取真实数据x中的一部分样本，将两部分导入判别器网络中，进行梯度计算和更新。而生成器网络的训练比较简单，直接采样获得小批量噪声样本，传入生成器后进行反向传播，更新生成器网络的梯度。  

还有一些对GAN的更新，比如给GAN增加一层CNN网络，从而使得图像更加清晰，生成的样本质量更高，分辨率也更高。GAN的种类相当之多，这里专门列了一页PPT，标题是GAN-ZOO……  

总结一下，GAN并不依赖显式的密度函数，而是使用博弈论的方法，通过两玩家游戏来学习从训练分布中生成新图像，其优点是生成的图像质量很高，可以说是最高的算法，但是其缺点是训练过程不稳定，这是由于交替训练两个网络造成的，另一个缺点是不能够解决一些对于p(x),p(z\|x)等中间过程变量值的相关查询。  


---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
