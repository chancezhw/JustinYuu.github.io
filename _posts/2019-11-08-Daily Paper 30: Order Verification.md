---
layout: post
title: "Daily Paper 30: Order Verification"
description: "Notes"
categories: [MMML-Self_Supervised]
tags: [Paper]
redirect_from:
  - /2019/11/08/
---

# Daily Paper 30 - Shuffle and Learn: Unsupervised Learning using Temporal Order Verification  

## Introduction  

这篇paper是CMU和FAIR合作的paper，发表在ECCV2016上。这篇paper的工作和之前的有所不同，主要用无监督学习方法通过时空信号来学习视频的视觉表示，应用到作者提出的时序验证任务中，具体来讲主要判断给定的视频帧序列是否是按照时间序列排列的。作者提出的这一模型学习到的表示，可以作为其他监督学习方法学习表示的补充，从而提高已有模型的性能，这主要是因为该表示能够学习到一些与时序有关的特征，比如人体的姿势。  

作者主要的motivation是想探索时空信号的功能，因此作者试图使用一种无监督学习的方式，在没有外部语义标注的情况下，让模型自己从视频中学习视频特征，看看模型能不能学习到一些有意义的信息，以及这些信息是否是传统监督方法学习不到，能与之进行互补的？  

在NLP领域，word2vec的发明使得模型可以学习到序列输入的分布式表示，CBOW等模型可以使得网络预测一个句子中给定位置的下一个单词，但是由于视频的每一个时间步都会有很多的像素，数据的维度相当高，所以预测视频某一时间步的下一帧是非常困难的。那么作者就退而求其次，将预测问题变成验证问题，让网络试图判断给定的一帧是不是当前时间步的下一帧，这类任务的复杂度看起来是可行的。训练完成之后，作者还将这一表示应用到动作识别和姿势估计中，并对为什么能够提升这两个下游任务的表现做出了解释：确定视频的时序需要对物体随时间的变化和相对位置进行理解，这导致该表示可以捕捉物体的出现和形变。  

## System  

作者首先定义正负样本，由于在视频的序列中，只有两个帧是不好排序的，比如拿起杯子和杯子在桌子上，杯子在桌子上那个片段究竟是拿起之前还是放下之后？这就会导致样本的模糊性，所以作者采取了将三个帧组成一组进行判断的方式，虽然三个帧也无法完全避免上述状况，但是作者会通过一个巧妙的采样方法来避免这个问题，采样方法稍后再说。这样对于一个未标注的视频V的n个帧f1...fn,作者取三个帧作为一个tuple(fb,fc,fd)，如果b<c<d或者d<c<b，那么就说明是时序正确的，否则是错误的，这里采取两个正确的判别准则也是因为尽可能的避免刚刚提到的三个帧时序模糊的问题。  

对于样本的采样方法，作者采取只对有高速运动的帧进行采样，这样可以避免由于变化很小导致的样本模糊问题，具体的采样方法是使用稀疏光流作为代理来判断，n定为5，从5个连续帧里面选任意三个组成一个tuple。选择正负样本的对比时需要注意要保证第一个和第三个相同，只改变中间帧的图像，这样可以使得网络更着重学习正负样本之间的不同点而不是其他无关的因素。那么这样五个帧选三个且起点和终点都相同，一共有3种选择，1种是正样本，两种为负样本，三个tuple结合起来作为一组进行训练。  

针对该采样方式，作者自然而然的选用了triplet loss作为损失函数，此外作者还使用了Siamese孪生网络，网络有三个平行的堆叠层，使用共享参数。网络的架构采用了类AlexNet的CaffeNet的conv1到fc7层，每一个堆叠层输入tuple中的一个帧，经过处理后在fc7层输出生成的表示，三个fc7层的输出concat起来输入到线性分类层中。在训练的时候作者使用三个平行的子网络，但是在测试的时候使用一个子网络就可以获得单个帧的每一层之后的特征表示，因为三个子网络的权重是相同的。  

## Experiments  

这里作者进行了相当多的实验，所以我这里根据每一个大部分进行分类说明。  

### Empirical Ablation Analysis  

首先对网络的一些架构设置进行了实验，这个实验使用UCF101数据集进行测试，使用分类准确率作为metric。作者首先进行了无监督学习的预训练，每一个tuple是3个帧，接下来使用一个spatial网络进行动作识别，具体细节不再复述。  

作者第一个研究的是采样参数，首先研究了正负样本各自起始端和终点端间的距离对tuple的预测准确率和动作识别率的影响，结果显示正样本的距离在60，负样本的距离在15的时候效果最好，这表明宽时序窗口对正样本来说更为适合，而窄时序窗口对负样本来说更为适合。接着作者又研究了正负样本的比例对结果的影响，最后发现负样本75%，正样本25%的时候tuple预测准确率和动作识别率最好。  

此外作者还进行了邻近查找，结果显示ImageNet预训练的网络找到的是场景语义相同的，而作者的无监督预训练网络主要是找到的相同姿势的图片，这种目标的不重合性说明了作者的无监督预训练网络能够很好的作为监督学习训练网络的补充，在理解场景语义的同时顺便学习到视频中随时间变化的姿势。  

### Action Recognition  

作者还进行了一系列关于动作识别的实验。之前的实验已经说明了作者的无监督学习方法能够学习到一些有意义的表示，那么这一部分的实验主要聚焦于评价该方法在动作识别这一下游任务上的表现。作者使用UCF101和HMDB51两个数据集，首先将该模型与随机初始化的模型进行对比，结果显然是远远超过随机初始化模型。接下来作者又将该模型和其他无监督学习方式的baseline进行对比，具体的baseline如下：作者的模型Three Order；将tuple里的3个帧改成两个的Two Order；给两个帧设定一个最小margin的DrLim；将DrLim距离计算方式由l2距离改成l1距离的TempCoh；以及一个公开的无监督方法Obj.Patch。结果显示作者的模型在两个数据集上的表现都是最好的，不过由于Obj.Patch没有在action data上预训练，所以其性能严格来讲没有完全发挥，所以参考价值并不是太大，不过其余模型的表现都不如作者的模型确实是真的。  

最后，作者将预训练的无监督模型和在ImageNet上预训练的模型结合起来，成为了最终的究极版本，结果显示究极版本比之前的单纯无监督模型平均准确率高了10%+，表明作者的模型能够有效的互补监督学习模型。  

### Pose Estimation Experiments  

作者最后对该模型在姿势估计任务的表现进行了实验，作者使用了FLIC和MPII数据集，对一个人的躯干标记6个关键点，然后使用Probability of Correct Keypoints(PCK)作为评价标准。作者用不同的初始化方式进行比较，使用ImageNet和UCF101上的预训练作为监督学习方法的baseline，使用作者的模型、Obj.Patch和DrLim上的预训练作为无监督学习baseline，结果显示作者的纯无监督模型能够获得与在ImageNet上监督学习方式预训练的模型相当的准确率，以及作者最终的究极版本的性能超过了所有的baseline，获得了最好的性能。  

## Conclusion  

作者主要尝试了用无监督学习的方法学习视频表示，结果显示模型能够通过时序信息和空间信息的内在联系学习到额外的有效表示，并能有效的与其他监督学习方法得到的结果相耦合。作者还提出了更多可能的方向，包括使用semi-supervised学习方式、学习光流信号、结合CNN和RNN等，而19年的现在回看16年作者提出的这些方向，大致都得到了一定的验证和发展。  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
