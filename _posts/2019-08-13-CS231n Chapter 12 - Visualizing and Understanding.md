---
layout: post
title: "CS231n Chapter 12 - Visualizing and Understanding"
description: "Notes"
categories: [CS231n]
tags: [Python]
redirect_from:
  - /2019/08/13/
---

# CS231n Chapter 12 - Visualizing and Understanding    

卷积神经网络的可视化一直是人们一直想要了解的问题，究竟在不同的卷积层内发生了什么？卷积神经网络中的不同部位又有什么作用呢？我们不仅仅满足于用work的卷积神经网络进行黑盒应用，而是力求可视化整个卷积神经网络，并理解每一层起到的具体作用，也就是图像经过每一层后产生的具体变化。  

第一层卷积层由多个filter组成，我们可以对卷积层的权重和图像的像素做点积，然后将结果作为图像显示出来，结果显示第一层卷积层基本在寻找有向边。如果我们直接在高层中可视化过滤器和权重，我们可能会看到一些图像，但是效果并不是很好，可解释性非常差，这是因为这些卷积层没有直接链接图像，所以我们需要寻找另外的方法来解释这些层。  

而网络的最后一层之前一般都是全连接层，然后输出到最后一层来预测得分，那么我们可以通过理解最后一层发生了什么来可视化和理解卷积神经网络，这里我们采用的是之前学习的Nearest Neighbor邻近算法。这里我们不再对每一个像素计算邻近了，而是对最后一层卷积层所产生的向量（这里是4096维）计算最近邻。这两种方法结果非常不同，虽然在像素层面上可能两者并不邻近，但是如果语义相同，在最后一层的向量上两者反而是邻近的，这也进一步说明了最后一层产生的特征空间的作用正是捕捉这些像素代表的语义内容。  

另一种表示最后一层的方法是PCA，即主成分分析，也可以用t-SNE进行可视化特征的非线性降维。这里给的例子是用t-SNE将minst数据集中的28×28维原始像素的4096维特征空间压缩到2×2，从而用图像来可视化。那么我们也可以用t-SNE这个方法来对上述最后一层产生的4096维向量进行可视化，从而得到最后一层的可视化结果。当然我们也可以用t-SNE对任意隐藏层进行可视化，不仅仅是最后一层。  

这里我们可以采取对激活层可视化的方式来尝试对中间层进行可视化。这里在AlexNet上，Conv5特征图是128×13×13的，我们可以将其看做128个13×13进行灰度图片可视化，从而看出CNN寻找的特征在输入数据中的对应位置。  

还有一种方式，叫做Maximally Activating Patches，通过将图像分成多个patches，观察哪一个patch能够激活最多不同的neurons和features。我们知道由于感知区域（感受野）的存在，每一个neuron能够对应的只是一个感受野，也就是整个图像中的一部分区域，那么我们所要可视化的，就是选择特定的一个layer的特定的一个feature，所能激活的MAP（最大激活区域）。我们可以从AlexNet的可视化实例中发现，低层激活的特征比较明显，而高层激活的特征更为高级，区域也更大，这是由于高层的感知区域比较大导致的。  

我们还可以使用遮挡实验，来确定具体是图像的哪一部分导致CNN进行图像的分类识别，我们用于遮挡的图像是这幅图像的平均像素值，然后将整个遮挡块滑过图像的每个位置，测量每一次的预测分数，作图，如果发现在某个地方发现了巨大变化，那么就说明这一部分对于CNN的分类决策起到了重要的影响。  

我们也可以用Silency Maps显著图来可视化的发现哪一部分起到了最重要的影响。显著图会计算输入图像像素的预测类别分数值的梯度，我们可以用GrabCut分割算法和显著图算法结合来更好的应用，不过这种算法有点脆弱，表现的效果要比原有的正确答案少很多。  

还有一种方法称作Intermediate features via (guided)backprop，我们选取中间层的一些neuron，然后看看图像的哪些patch影响了中间层的神经元的反向传播分值。也就是说，我们不观察最后的得分，而是进而关注中间层每一个神经元的得分，称作引导反向传播的原因就是我们需要手动的反向传播来找到具体的中间层得分。此外我们只需要记录正梯度，这些是有积极影响的因素，而负梯度不需要记录。  

上面的所有操作，都是在研究输入图像的哪一部分影响了神经元的最终分数，但是如果我们如果去除了图像的依赖性，输入的类型又是怎么影响神经元的呢？这里我们可以用梯度上升来解决这个问题，之前我们都是使用梯队下降来优化我们的CNN，这里我们采取相反的方式，用梯度上升来应用CNN的权重生成一组新的图片，此外我们还试图改变图像的像素，从而使得某些中间神经元的分数值最大化。在梯度上升的过程中，我们不再优化W。这里我们还会使用正则化的思想，从而使得我们的生成图像避免存在一些过拟合的特性，看起来像一个正常的图像。我们的正向传播计算当前的得分，然后运用反向传播计算得分对像素的梯度，对该值进行一个梯度上升的更新（也有可能是下降），最后生成一个完整的图像。  

这里我们使用的是L2范数来进行正则化，但是这在语义上来说并没有什么意义，最后生成的图像也实在是一言难尽……所以我们需要用其他的方法来改进我们的可视化结果。我们定期的对图像进行高斯模糊，并同时把一些低梯度的像素设置为0，也将一些低分数的像素设置为0，这时生成的结果看起来干净了一些，虽然还是一言难尽……最后的进一步优化是最大化某个中间层的其中一个神经元分数值，而不是对某个特定label的最后分数值进行优化，这种从中间开始优化的方式反而会得到更好的结果。  

我们还可以用Fooling Image和Adversarial Example对抗样本的方法来解决问题，首先是愚弄图像，我们会选一张大象的图片，然后告诉CNN这张图片中考拉的分数值，然后我们要改变这个大象的形象，让神经网络将其归为考拉……可是结果是图片看起来并没有什么改变，这是因为虽然在像素上看起来没有差异，但是它们是实际存在差异的，放大之后我们会发现差异就像随机的噪声模型，并没有考拉和大象的特征，具体的原因将会在后面对抗网络中Goodfellow解释。  

这里有stanford的学生提问，我们试图理解中间层的作用是什么？这其实是对外界对深度学习领域的质疑的一个回应，大家都认为深度学习是炼丹，我们在一个很深的神经网络中训练，得到一个好的结果，但是我们并不相信这个网络，因为它很难解释，呼应这篇文章开头我写到的，就像一个大黑盒。那么这里要做的事情就是尝试去解释这个复杂的网络内部，其不同的层级究竟在做什么，这其实是很有意义的。  

DeepDream是一个用于放大已知特性的算法，我们将所选图片放入神经网络中，前向传播到某一特定的层，然后反向传播并设置该层的梯度为激活值，接下来不断的反向传播，更新图像，这么做的原因是我们要放大神经网络在这张图像中检测到的特征，我们会使用L1均一化来正则化。通过DeepDream，我们可以生成很多疯狂的图像。  

Feature Inversion是一种重构图片的方式，我们通过记录CNN中某一层的具体特征，然后生成一个与该特征匹配的新图像，从而得到不同层之间该特征的信息存储量。我们会发现比较浅层的隐藏层并不会丢弃掉该特征的太多存储信息，但是到更深处的时候，一些低层次的细节更容易损失。  

Feature Inversion神经迁移中会得到广泛的应用，但是除此之外还需要用到的一种技术叫做Texture Synthesis纹理合成，纹理合成顾名思义，就是选取一小块色素，然后生成一大块同样的色素。我个人的想法是复制粘贴就可以……这里的方式也很简单，就是用了一种很简单的算法，按照扫描线遍历生成像素，然后根据已生成的像素查看当前像素周围的邻域，并在输入图像的图像块中计算近邻，然后从输入图像中复制像素。但是问题是当纹理复杂的时候，这个算法就会失灵，所以我们采用神经网络的方式。  

这里使用了一个gram matrix的概念，通过将纹理导入卷积神经网络中，选取在CNN中某层的特征。具体方法是我们用激活映射图来计算纹理映射符，然后选出输入特征的两种不同功能列，将这两个列做外积得到C×C的矩阵，然后将所有的C×C矩阵取平均，即可得到我们的gram matrix，表示输入图像的纹理结构。值得注意的是使用协方差矩阵也能达到相同的效果，只不过计算成本更高一些。在具体的计算过程中，我们首先在VGG Net上预处理一个CNN，然后将输入的纹理结构导入CNN中，记录每一层的激活函数值，并保存每一层的特征图。之后在每一层计算Gram matrix，接着随机初始化我们的生成图片。这个位置记为标记1，那么我们接下来开始将生成的图片传入CNN中，计算每一层的gram matrix，然后与之前计算的gram matrix作对比，计算L2距离，加权得到loss值，接下来反向传播，得到在图像像素上的梯度，并更新像素值，接下来回到标记1的位置，不断循环直至loss收敛为极小值。从示例上看，在实际操作中，前面几层的生成结果只保留了颜色和斑点，并没有保持整体的结构，但是在较高层的位置，我们会得到与原图像更为相似的结果。    

学完了Feature Inversion和Texture Synthesis这两个算法，我们可以进行更为有趣和强大的功能：神经风格转移。神经风格转移的计算方法极其复杂，在之前吴恩达CNN MOOC中提到过，这里我把当时的笔记链接放在[这里](http://justin-yu.me/blog/2019/07/03/Convolutional-Neural-Networks-Chapter-4/)。和DeepDream相比，神经风格转移是一种更为可控的风格生成算法，生成的图像更为美观整洁。不过它也存在一定的问题：太慢……这里的解决方式是用另一个神经网络来做风格迁移的工作，不过这个貌似就是吴恩达介绍的方法。  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
