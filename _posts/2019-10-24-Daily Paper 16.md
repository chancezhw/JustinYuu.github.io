---
layout: post
title: "Daily Paper 16"
description: "Notes"
categories: [CV-classic]
tags: [Paper]
redirect_from:
  - /2019/10/24/
---

# Daily Paper 16 - Visualizing and understanding convolutional networks  

## Introduction  

今天的paper是研究CNN可视化的经典之作。CNN一直以来被看做是一个有效的黑盒子，但是具体的原理，或者说不同层之间的处理方式，以及CNN为何是有效的一直是未知的，这里作者就希望能够同时解决这两个问题，并对CNN进行可视化。作者可视化了AlexNet在ImageNet上的表现，此外还分别研究了每一层对整体的贡献。最后，作者还研究了ImageNet的泛化性能，结果显示ImageNet的泛化性能很好，并且在Caltech-256和Caltech-101上的结果优于其他结果。  

近年来，CNN发展的越来越好，这主要是因为数据集规模的不断扩大、GPU训练能力的不断提升，以及新的有效的正则化方法不断出现，例如dropout。不过对于这些复杂模型内部的原理探究仍然少之又少，如果不知道原理进行研究，那么只能通过不断的试错才能发现更好的方法，这很明显是不够科学的。作者在这篇paper中介绍了一种新型的可视化方法，从而可以探究特征在不同的层中的表现，作者采用的是多层反卷积，将特征激活值投影到输入空间内。作者还通过遮挡部分图像的方式来探究图像的不同部分对最终的结果产生的影响，从而探究图像的哪些部分对于分类来说最为重要。用上述工具，作者使用AlexNet进行ImageNet上的可视化研究，并探究了该模型的泛化性能。  

## System  

作者基本使用AlexNet作为实验的网络，只是对softmax分类层进行了一些修改。作者使用了反卷积进行了可视化，反卷积的作用就是为了把最后的特征映射回原有的输入像素空间，研究输入的原始图像是如何转变为特征图中的激活值的。所谓反卷积，就是使用完全相同的过滤器和池化层，只不过将整个方向反过来，将特征映射为像素，在之前Zeiler的论文中，这被用来进行无监督学习，而在这里并不用于学习，而仅仅用于训练完毕的卷积层的可视化。反卷积的具体方式如下：首先将原始图像导入到卷积网络中得到特征图，接下来将其他所有的权重全部设置为0，只保留需要研究的那一层，最后做三步操作：反池化、recitify、使用过滤器反卷积，重复这三部直到输入的像素空间显现为止。  

首先是反池化，池化操作是不可逆的，这个显而易见。那么反池化的操作就是在池化的过程中保留最大值的位置，在反池化的过程中将最大值放置在保存的那个位置即可。其次是ReLU，这个没什么特别的，直接用就好。最后是卷积，这里使用同一个卷积核的转置就可以完成，这相当于垂直和水平方向各翻转了卷积核一次。  

## Experiments  

接下来就进行了卷积层的可视化。训练结束后，输出模型各个隐藏层提取的特征，同时输出给定输出特征时，反卷积产生的最强的9个输入特征。将这些计算所得的特征，用像素空间表示后，可以清晰地看出：一组特定的输入特征（通过重构获得），将刺激卷积网产生一个固定的输出特征。对应的输入图片，和重构特征相比，输入图片和其之间的差异性很大，而重构特征只包含那些具有判别能力的纹理结构。每一层的可视化结果都展示了网络的层次化特点。第2层展示了物体的边缘和轮廓，以及与颜色的组合，第3层拥有了更复杂的不变性，主要展示了相似的纹理，第4层不同组重构特征存在着重大差异性，开始体现了类与类之间的差异，第5层每组图片都展示了存在重大差异的一类物体。  

同时还得出了一些特征的不变性，作者用一幅图列出了5个不同的例子，它们分别被平移、旋转和缩放。用一张对比图显示了不同层特征向量所具有的不变性能力。在第一层，很小的微变都会导致输出特征变化明显，但是越往高层走，平移和尺度变化对最终结果的影响越小。卷积网无法对旋转操作产生不变性，除非物体具有很强的对称性。  

作者同时做了一些遮挡敏感性的实验，首先随机用灰块遮挡了图像的一部分像素，然后进行可视化分析，结果显示当物体被遮住的时候能够被识别的几率会大大降低。  

深度学习和其他识别算法明显不同的一点是它并没有明显的联系不同图片中的相同类型的物体，但是作者猜测可能在内部会有隐式的联系。因此作者选了5个狗的图片，然后遮住了狗狗脸的同一个部位，计算遮挡前和遮挡后的向量差，之后比较不同向量差之间的海明距离。结果显示海明距离很小，那么可以得出遮挡操作会有高度类似的影响，进而说明不同图像中的相同部位会有内部的联系。  

该模型在ImageNet上得到了14.8%的错误率，这是当今最好的表现，在Caltech-101上泛化得到了83.8%的15img/class准确率，86.5%的30img/class准确率，均远远超过其他模型，在Caltech-256上泛化，15、30、45、60img/class准确率分别为65.7、70.6、72.7、74.2%，也远远超过其他模型的泛化表现。  

## Conclusion  

总结一下，作者提出了一套可视化卷积神经网络的方法，并可视化了AlexNet，探究了不同层以及原始图像中的不同部位对特征空间的影响，并探究了不同图像中的相同位置的隐含联系。此外，作者还研究了该模型的泛化性能，结果显示其泛化性能优秀，得到的泛化结果显著的优于当时其他所有模型。  

---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
