---
layout: post
title: "Daily Paper 14"
description: "Notes"
categories: [CV-classic]
tags: [Paper]
redirect_from:
  - /2019/10/22/
---

# Daily Paper 14 - Yolo_You Only Look Once Unified,Real-Time Object Detection  

## Introduction  

今天读的paper是YOLO，一种非常经典的目标检测的算法。在之前，目标检测问题都会被当做成分类问题来处理，而这里作者将其看成分割边界框和连接类概率的回归问题。作者使用一个神经网络用一次估计来直接从原图像中判断边框和类概率。作者提出的模型速度非常快，YOLO模型可以在一秒内实时处理45帧，另一个较小的网络Fast YOLO可以在一秒内实时处理155帧并保持mAP是其他目标检测算法的两倍。与目前的检测系统相比，YOLO有更高的定位错误率，但是会有更少的false positive发生。最后，YOLO有很好的泛化能力，能够在其他领域的自然图像处理中有优于其他算法的表现。  

能够媲美人眼目标检测的机器学习算法是非常必要的，在自动驾驶、人工辅助设备、机器人等众多领域，实时检测都是必不可少的。在这篇paper发出之前，大家采用的目标检测算法都是通过对图像中的物体分类定位实现的，比如DPM，采用滑动窗口分别识别图片中的各个部分，或者R-CNN，采用region proposal方法生成潜在的边框，然后通过一个分类器对边框中的物体进行分类识别。这种方法速度非常慢，并且很难优化，因为每一个个体的组成部分都需要分别训练。  

而作者将目标检测问题看成了一个回归问题，将图像的原始像素和边框坐标和类概率直接对应起来，因此You Only Look Once就可以完成物体识别和定位两部分功能，所以该系统起名为YOLO。YOLO其实很简单，首先resize图像，然后用一个CNN处理，进行非最大抑制，将检测结果限制在置信区间内。这种方式相对于传统方式有三大优点：第一，快，在实际应用中可以达到在25微秒的延迟内完成处理；第二，YOLO采用整体的图像进行处理，那么相对于传统的滑动窗口来说，看到的信息就更为全面，因此可以获得更多原始信息；第三，YOLO可以学习到物体的可泛化的表示，从而具有高度的可泛化性。  

不过作者也承认，YOLO速度虽然快，但是准确率仍然距离主流的目标检测算法有差距，主要原因是它可以迅速准确的识别，但是无法准确的定位，特别是小物体。作者在后续的工作中会不断完善改进这一部分。  

## System  

接下来看YOLO的网络架构细节。YOLO将原始图片分成S×S的网格，如果物体的中心在某个网格中，那么那个网格就负责来检测该物体。每一个网格预测B个边框和这些边框的置信分数，置信度分数代表该边框内含有物体的可能性和边框内物体预测的准确度，表示为Pr(Object)\*IOU，其中Pr只有0和1之分。每一个边框内含有5个预测值：x,y,w,h和置信度，(x,y)代表坐标，w,h代表宽和高，置信度就是前面说的Pr\*IOU。此外，每一个网格也预测C个条件类概率，记作Pr(Class<sub>i</sub>\|Object)，一个网格只预测一个类的概率，不管有多少个边框B，最后将条件概率与前面的置信度分数乘起来，即得到了Pr(Class<sub>i</sub>)\*IOU的值，也就是特定类在每个边框的置信度。  

接下来是CNN的架构，卷积层用来提取特征，FC用来预测坐标和概率。YOLO使用的架构灵感来源于昨天介绍的GoogLeNet，网络共有24个卷积层后缀最大池化，2个FC层，不过并没有采取inception架构，而是使用了NIN模型中的3×3卷积层后缀1×1降维层。此外，作者还训练了一个Fast版本的YOLO，Fast YOLO共有9个卷积层，内部的filter数量也相应变少，所有的测试和训练的参数都和YOLO相同。  

作者现在ImageNet上进行卷积层的预训练，达到了ILSVRC12测试集上的88%准确率，预训练的层数只有20+1，预训练之后再将后面的4+1加起来，后加的这几层权重随机初始化。所有的非线性激活函数使用leaky ReLU，leaky参数为0.1，使用平方误差，不过虽然优化起来很简单，但是和我们最大化平均准确率的目标并不太吻合，它将定位误差和分类误差完全等同，但是这可能不太合适。此外，很多网格里面可能并不含有物体，置信度公式中得出的结果便为0，从而overpower那些真正含有物体的网格的梯度，从而导致训练有可能提前收敛。  


---
本博客支持disqus实时评论功能，如有错误或者建议，欢迎在下方评论区提出，共同探讨。  
